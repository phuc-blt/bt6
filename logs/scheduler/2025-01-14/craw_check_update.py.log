[2025-01-14T00:00:21.424+0000] {processor.py:186} INFO - Started process (PID=35630) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:00:21.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:00:21.429+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:00:21.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:00:23.924+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:00:23.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:00:23.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:00:23.962+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:00:23.962+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:00:23.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.560 seconds
[2025-01-14T00:00:54.231+0000] {processor.py:186} INFO - Started process (PID=35698) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:00:54.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:00:54.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:00:54.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:00:56.663+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:00:56.678+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:00:56.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:00:56.700+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:00:56.700+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:00:56.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.491 seconds
[2025-01-14T00:01:27.539+0000] {processor.py:186} INFO - Started process (PID=35765) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:01:27.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:01:27.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:01:27.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:01:30.045+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:01:30.062+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:01:30.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:01:30.083+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:01:30.083+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:01:30.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.565 seconds
[2025-01-14T00:02:00.950+0000] {processor.py:186} INFO - Started process (PID=35832) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:02:00.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:02:00.954+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:02:00.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:02:03.365+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:02:03.384+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:02:03.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:02:03.410+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:02:03.410+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:02:03.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.489 seconds
[2025-01-14T00:02:34.358+0000] {processor.py:186} INFO - Started process (PID=35903) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:02:34.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:02:34.362+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:02:34.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:02:36.879+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:02:36.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:02:36.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:02:36.916+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:02:36.916+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:02:36.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.579 seconds
[2025-01-14T00:03:07.088+0000] {processor.py:186} INFO - Started process (PID=35986) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:03:07.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:03:07.093+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:03:07.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:03:09.500+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:03:09.515+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:03:09.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:03:09.535+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:03:09.535+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:03:09.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.470 seconds
[2025-01-14T00:03:39.849+0000] {processor.py:186} INFO - Started process (PID=36058) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:03:39.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:03:39.853+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:03:39.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:03:42.293+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:03:42.308+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:03:42.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:03:42.329+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:03:42.329+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:03:42.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.502 seconds
[2025-01-14T00:04:12.919+0000] {processor.py:186} INFO - Started process (PID=36133) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:04:12.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:04:12.923+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:04:12.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:04:15.281+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:04:15.295+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:04:15.295+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:04:15.315+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:04:15.315+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:04:15.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.417 seconds
[2025-01-14T00:04:45.413+0000] {processor.py:186} INFO - Started process (PID=36199) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:04:45.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:04:45.418+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:04:45.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:04:47.799+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:04:47.817+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:04:47.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:04:47.836+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:04:47.836+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:04:47.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.446 seconds
[2025-01-14T00:05:18.817+0000] {processor.py:186} INFO - Started process (PID=36265) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:05:18.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:05:18.821+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:05:18.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:05:21.183+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:05:21.198+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:05:21.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:05:21.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:05:21.218+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:05:21.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.422 seconds
[2025-01-14T00:05:51.396+0000] {processor.py:186} INFO - Started process (PID=36330) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:05:51.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:05:51.400+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:05:51.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:05:53.773+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:05:53.789+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:05:53.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:05:53.809+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:05:53.808+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:05:53.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T00:06:24.047+0000] {processor.py:186} INFO - Started process (PID=36395) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:06:24.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:06:24.052+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:06:24.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:06:26.418+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:06:26.436+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:06:26.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:06:26.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:06:26.455+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:06:26.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.432 seconds
[2025-01-14T00:06:57.004+0000] {processor.py:186} INFO - Started process (PID=36459) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:06:57.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:06:57.008+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:06:57.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:06:59.422+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:06:59.438+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:06:59.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:06:59.458+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:06:59.458+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:06:59.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.476 seconds
[2025-01-14T00:07:29.763+0000] {processor.py:186} INFO - Started process (PID=36527) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:07:29.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:07:29.768+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:07:29.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:07:32.165+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:07:32.182+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:07:32.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:07:32.201+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:07:32.201+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:07:32.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.461 seconds
[2025-01-14T00:08:02.507+0000] {processor.py:186} INFO - Started process (PID=36595) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:08:02.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:08:02.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:08:02.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:08:04.913+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:08:04.930+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:08:04.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:08:04.951+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:08:04.951+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:08:04.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.465 seconds
[2025-01-14T00:08:35.098+0000] {processor.py:186} INFO - Started process (PID=36666) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:08:35.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:08:35.102+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:08:35.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:08:37.485+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:08:37.501+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:08:37.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:08:37.523+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:08:37.522+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:08:37.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.446 seconds
[2025-01-14T00:09:08.534+0000] {processor.py:186} INFO - Started process (PID=36733) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:09:08.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:09:08.539+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:09:08.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:09:10.874+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:09:10.890+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:09:10.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:09:10.910+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:09:10.910+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:09:10.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.400 seconds
[2025-01-14T00:09:41.782+0000] {processor.py:186} INFO - Started process (PID=36797) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:09:41.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:09:41.787+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:09:41.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:09:44.127+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:09:44.143+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:09:44.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:09:44.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:09:44.165+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:09:44.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.406 seconds
[2025-01-14T00:10:15.111+0000] {processor.py:186} INFO - Started process (PID=36860) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:10:15.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:10:15.115+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:10:15.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:10:17.524+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:10:17.539+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:10:17.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:10:17.560+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:10:17.560+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:10:17.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.471 seconds
[2025-01-14T00:10:47.918+0000] {processor.py:186} INFO - Started process (PID=36931) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:10:47.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:10:47.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:10:47.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:10:50.308+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:10:50.324+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:10:50.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:10:50.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:10:50.345+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:10:50.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.448 seconds
[2025-01-14T00:11:20.562+0000] {processor.py:186} INFO - Started process (PID=37002) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:11:20.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:11:20.566+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:11:20.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:11:22.891+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:11:22.906+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:11:22.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:11:22.928+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:11:22.928+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:11:22.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.389 seconds
[2025-01-14T00:11:53.743+0000] {processor.py:186} INFO - Started process (PID=37066) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:11:53.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:11:53.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:11:53.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:11:56.096+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:11:56.112+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:11:56.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:11:56.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:11:56.131+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:11:56.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.412 seconds
[2025-01-14T00:12:27.191+0000] {processor.py:186} INFO - Started process (PID=37130) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:12:27.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:12:27.194+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:12:27.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:12:29.542+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:12:29.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:12:29.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:12:29.585+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:12:29.584+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:12:29.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.440 seconds
[2025-01-14T00:13:00.454+0000] {processor.py:186} INFO - Started process (PID=37194) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:13:00.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:13:00.459+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:13:00.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:13:02.929+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:13:02.946+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:13:02.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:13:02.965+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:13:02.965+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:13:02.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.539 seconds
[2025-01-14T00:13:33.297+0000] {processor.py:186} INFO - Started process (PID=37271) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:13:33.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:13:33.301+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:13:33.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:13:35.751+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:13:35.767+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:13:35.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:13:35.787+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:13:35.787+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:13:35.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.511 seconds
[2025-01-14T00:14:06.356+0000] {processor.py:186} INFO - Started process (PID=37356) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:14:06.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:14:06.360+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:14:06.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:14:08.750+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:14:08.768+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:14:08.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:14:08.789+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:14:08.789+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:14:08.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.458 seconds
[2025-01-14T00:14:39.820+0000] {processor.py:186} INFO - Started process (PID=37422) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:14:39.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:14:39.825+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:14:39.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:14:42.224+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:14:42.240+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:14:42.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:14:42.260+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:14:42.259+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:14:42.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.462 seconds
[2025-01-14T00:15:12.386+0000] {processor.py:186} INFO - Started process (PID=37497) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:15:12.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:15:12.390+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:15:12.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:15:14.715+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:15:14.729+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:15:14.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:15:14.748+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:15:14.748+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:15:14.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.386 seconds
[2025-01-14T00:15:45.557+0000] {processor.py:186} INFO - Started process (PID=37562) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:15:45.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:15:45.561+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:15:45.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:15:47.924+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:15:47.939+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:15:47.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:15:47.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:15:47.959+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:15:47.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.423 seconds
[2025-01-14T00:16:18.356+0000] {processor.py:186} INFO - Started process (PID=37626) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:16:18.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:16:18.360+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:16:18.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:16:20.764+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:16:20.784+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:16:20.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:16:20.804+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:16:20.804+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:16:20.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.471 seconds
[2025-01-14T00:16:50.921+0000] {processor.py:186} INFO - Started process (PID=37691) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:16:50.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:16:50.925+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:16:50.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:16:53.384+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:16:53.399+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:16:53.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:16:53.420+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:16:53.420+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:16:53.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.520 seconds
[2025-01-14T00:17:24.122+0000] {processor.py:186} INFO - Started process (PID=37767) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:17:24.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:17:24.126+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:17:24.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:17:26.483+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:17:26.498+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:17:26.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:17:26.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:17:26.517+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:17:26.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.419 seconds
[2025-01-14T00:17:57.582+0000] {processor.py:186} INFO - Started process (PID=37833) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:17:57.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:17:57.587+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:17:57.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:17:59.943+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:17:59.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:17:59.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:17:59.980+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:17:59.980+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:17:59.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.419 seconds
[2025-01-14T00:18:30.086+0000] {processor.py:186} INFO - Started process (PID=37897) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:18:30.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:18:30.091+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:18:30.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:18:32.439+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:18:32.454+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:18:32.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:18:32.473+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:18:32.473+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:18:32.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.410 seconds
[2025-01-14T00:19:03.067+0000] {processor.py:186} INFO - Started process (PID=37961) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:19:03.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:19:03.071+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:19:03.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:19:05.412+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:19:05.428+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:19:05.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:19:05.446+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:19:05.446+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:19:05.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.403 seconds
[2025-01-14T00:19:35.782+0000] {processor.py:186} INFO - Started process (PID=38031) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:19:35.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:19:35.786+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:19:35.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:19:38.191+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:19:38.206+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:19:38.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:19:38.224+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:19:38.224+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:19:38.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.464 seconds
[2025-01-14T00:20:08.550+0000] {processor.py:186} INFO - Started process (PID=38095) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:20:08.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:20:08.554+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:20:08.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:20:10.903+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:20:10.918+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:20:10.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:20:10.938+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:20:10.937+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:20:10.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.409 seconds
[2025-01-14T00:20:41.251+0000] {processor.py:186} INFO - Started process (PID=38159) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:20:41.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:20:41.256+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:20:41.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:20:43.596+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:20:43.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:20:43.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:20:43.629+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:20:43.629+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:20:43.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.400 seconds
[2025-01-14T00:21:14.051+0000] {processor.py:186} INFO - Started process (PID=38223) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:21:14.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:21:14.055+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:21:14.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:21:16.385+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:21:16.400+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:21:16.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:21:16.420+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:21:16.420+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:21:16.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.392 seconds
[2025-01-14T00:21:46.835+0000] {processor.py:186} INFO - Started process (PID=38287) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:21:46.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:21:46.839+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:21:46.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:21:49.221+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:21:49.238+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:21:49.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:21:49.258+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:21:49.257+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:21:49.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.449 seconds
[2025-01-14T00:22:19.521+0000] {processor.py:186} INFO - Started process (PID=38352) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:22:19.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:22:19.526+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:22:19.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:22:22.013+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:22:22.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:22:22.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:22:22.056+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:22:22.056+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:22:22.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.559 seconds
[2025-01-14T00:22:52.216+0000] {processor.py:186} INFO - Started process (PID=38433) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:22:52.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:22:52.220+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:22:52.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:22:54.662+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:22:54.682+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:22:54.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:22:54.702+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:22:54.702+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:22:54.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.510 seconds
[2025-01-14T00:23:25.664+0000] {processor.py:186} INFO - Started process (PID=38513) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:23:25.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:23:25.668+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:23:25.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:23:28.138+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:23:28.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:23:28.154+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:23:28.175+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:23:28.174+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:23:28.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.534 seconds
[2025-01-14T00:23:58.313+0000] {processor.py:186} INFO - Started process (PID=38592) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:23:58.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:23:58.317+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:23:58.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:24:00.734+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:24:00.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:24:00.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:24:00.770+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:24:00.769+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:24:00.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.479 seconds
[2025-01-14T00:24:30.898+0000] {processor.py:186} INFO - Started process (PID=38662) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:24:30.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:24:30.902+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:24:30.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:24:33.252+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:24:33.268+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:24:33.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:24:33.287+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:24:33.287+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:24:33.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.412 seconds
[2025-01-14T00:25:04.155+0000] {processor.py:186} INFO - Started process (PID=38727) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:25:04.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:25:04.160+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:25:04.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:25:06.498+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:25:06.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:25:06.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:25:06.534+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:25:06.534+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:25:06.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.401 seconds
[2025-01-14T00:25:37.030+0000] {processor.py:186} INFO - Started process (PID=38797) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:25:37.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:25:37.034+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:25:37.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:25:39.386+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:25:39.401+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:25:39.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:25:39.422+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:25:39.421+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:25:39.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.414 seconds
[2025-01-14T00:26:10.070+0000] {processor.py:186} INFO - Started process (PID=38861) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:26:10.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:26:10.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:26:10.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:26:12.410+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:26:12.426+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:26:12.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:26:12.445+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:26:12.445+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:26:12.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.397 seconds
[2025-01-14T00:26:42.601+0000] {processor.py:186} INFO - Started process (PID=38925) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:26:42.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:26:42.605+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:26:42.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:26:44.946+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:26:44.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:26:44.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:26:44.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:26:44.980+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:26:44.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.400 seconds
[2025-01-14T00:27:15.605+0000] {processor.py:186} INFO - Started process (PID=38990) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:27:15.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:27:15.609+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:27:15.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:27:17.965+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:27:17.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:27:17.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:27:18.003+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:27:18.003+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:27:18.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.420 seconds
[2025-01-14T00:27:48.261+0000] {processor.py:186} INFO - Started process (PID=39054) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:27:48.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:27:48.265+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:27:48.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:27:50.629+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:27:50.645+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:27:50.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:27:50.667+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:27:50.667+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:27:50.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.429 seconds
[2025-01-14T00:28:20.907+0000] {processor.py:186} INFO - Started process (PID=39118) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:28:20.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:28:20.911+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:28:20.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:28:23.261+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:28:23.277+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:28:23.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:28:23.298+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:28:23.298+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:28:23.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.413 seconds
[2025-01-14T00:28:53.435+0000] {processor.py:186} INFO - Started process (PID=39182) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:28:53.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:28:53.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:28:53.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:28:55.814+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:28:55.837+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:28:55.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:28:55.856+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:28:55.856+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:28:55.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.444 seconds
[2025-01-14T00:29:26.033+0000] {processor.py:186} INFO - Started process (PID=39249) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:29:26.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:29:26.037+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:29:26.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:29:28.411+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:29:28.426+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:29:28.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:29:28.445+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:29:28.444+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:29:28.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.432 seconds
[2025-01-14T00:29:59.243+0000] {processor.py:186} INFO - Started process (PID=39314) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:29:59.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:29:59.248+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:29:59.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:30:01.608+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:30:01.625+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:30:01.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:30:01.645+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:30:01.644+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:30:01.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.423 seconds
[2025-01-14T00:30:31.821+0000] {processor.py:186} INFO - Started process (PID=39378) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:30:31.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:30:31.825+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:30:31.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:30:34.246+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:30:34.261+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:30:34.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:30:34.281+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:30:34.280+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:30:34.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.481 seconds
[2025-01-14T00:31:04.611+0000] {processor.py:186} INFO - Started process (PID=39445) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:31:04.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:31:04.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:31:04.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:31:07.041+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:31:07.065+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:31:07.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:31:07.086+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:31:07.086+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:31:07.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.498 seconds
[2025-01-14T00:31:37.181+0000] {processor.py:186} INFO - Started process (PID=39520) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:31:37.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:31:37.186+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:31:37.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:31:39.552+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:31:39.569+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:31:39.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:31:39.589+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:31:39.589+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:31:39.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.429 seconds
[2025-01-14T00:32:09.699+0000] {processor.py:186} INFO - Started process (PID=39584) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:32:09.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:32:09.703+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:32:09.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:32:12.121+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:32:12.143+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:32:12.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:32:12.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:32:12.165+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:32:12.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.489 seconds
[2025-01-14T00:32:42.372+0000] {processor.py:186} INFO - Started process (PID=39655) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:32:42.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:32:42.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:32:42.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:32:44.885+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:32:44.904+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:32:44.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:32:44.928+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:32:44.927+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:32:44.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.580 seconds
[2025-01-14T00:33:15.032+0000] {processor.py:186} INFO - Started process (PID=39732) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:33:15.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:33:15.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:33:15.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:33:17.624+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:33:17.642+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:33:17.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:33:17.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:33:17.661+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:33:17.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.653 seconds
[2025-01-14T00:33:47.779+0000] {processor.py:186} INFO - Started process (PID=39817) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:33:47.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:33:47.783+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:33:47.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:33:50.276+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:33:50.291+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:33:50.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:33:50.310+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:33:50.310+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:33:50.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.553 seconds
[2025-01-14T00:34:20.712+0000] {processor.py:186} INFO - Started process (PID=39881) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:34:20.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:34:20.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:34:20.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:34:23.203+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:34:23.220+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:34:23.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:34:23.241+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:34:23.241+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:34:23.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.553 seconds
[2025-01-14T00:34:54.105+0000] {processor.py:186} INFO - Started process (PID=39945) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:34:54.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:34:54.109+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:34:54.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:34:56.626+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:34:56.642+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:34:56.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:34:56.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:34:56.661+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:34:56.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.578 seconds
[2025-01-14T00:35:26.986+0000] {processor.py:186} INFO - Started process (PID=40011) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:35:26.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:35:26.990+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:35:26.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:35:29.496+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:35:29.513+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:35:29.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:35:29.532+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:35:29.532+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:35:29.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.568 seconds
[2025-01-14T00:36:00.028+0000] {processor.py:186} INFO - Started process (PID=40074) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:36:00.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:36:00.032+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:36:00.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:36:02.605+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:36:02.620+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:36:02.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:36:02.639+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:36:02.639+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:36:02.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.634 seconds
[2025-01-14T00:36:32.976+0000] {processor.py:186} INFO - Started process (PID=40142) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:36:32.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:36:32.980+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:36:32.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:36:35.577+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:36:35.598+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:36:35.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:36:35.627+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:36:35.627+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:36:35.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.713 seconds
[2025-01-14T00:37:06.261+0000] {processor.py:186} INFO - Started process (PID=40212) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:37:06.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:37:06.265+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:37:06.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:37:08.792+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:37:08.809+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:37:08.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:37:08.829+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:37:08.828+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:37:08.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.592 seconds
[2025-01-14T00:37:39.032+0000] {processor.py:186} INFO - Started process (PID=40278) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:37:39.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:37:39.035+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:37:39.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:37:41.630+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:37:41.648+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:37:41.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:37:41.668+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:37:41.667+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:37:41.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.659 seconds
[2025-01-14T00:38:12.668+0000] {processor.py:186} INFO - Started process (PID=40349) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:38:12.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:38:12.672+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:38:12.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:38:15.180+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:38:15.197+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:38:15.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:38:15.217+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:38:15.216+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:38:15.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.571 seconds
[2025-01-14T00:38:45.806+0000] {processor.py:186} INFO - Started process (PID=40414) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:38:45.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:38:45.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:38:45.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:38:48.393+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:38:48.410+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:38:48.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:38:48.429+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:38:48.429+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:38:48.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.645 seconds
[2025-01-14T00:39:18.731+0000] {processor.py:186} INFO - Started process (PID=40486) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:39:18.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:39:18.735+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:39:18.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:39:21.430+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:39:21.447+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:39:21.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:39:21.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:39:21.467+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:39:21.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.761 seconds
[2025-01-14T00:39:51.712+0000] {processor.py:186} INFO - Started process (PID=40563) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:39:51.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:39:51.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:39:51.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:39:54.449+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:39:54.466+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:39:54.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:39:54.485+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:39:54.485+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:39:54.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.795 seconds
[2025-01-14T00:40:25.436+0000] {processor.py:186} INFO - Started process (PID=40643) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:40:25.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:40:25.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:40:25.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:40:27.979+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:40:27.995+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:40:27.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:40:28.015+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:40:28.014+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:40:28.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.613 seconds
[2025-01-14T00:40:58.239+0000] {processor.py:186} INFO - Started process (PID=40710) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:40:58.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:40:58.243+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:40:58.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:41:00.652+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:41:00.668+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:41:00.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:41:00.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:41:00.688+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:41:00.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.472 seconds
[2025-01-14T00:41:30.778+0000] {processor.py:186} INFO - Started process (PID=40775) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:41:30.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:41:30.782+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:41:30.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:41:33.153+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:41:33.167+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:41:33.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:41:33.187+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:41:33.187+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:41:33.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.431 seconds
[2025-01-14T00:42:04.069+0000] {processor.py:186} INFO - Started process (PID=40839) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:42:04.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:42:04.073+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:42:04.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:42:06.473+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:42:06.491+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:42:06.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:42:06.511+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:42:06.511+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:42:06.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.465 seconds
[2025-01-14T00:42:36.625+0000] {processor.py:186} INFO - Started process (PID=40903) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:42:36.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:42:36.630+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:42:36.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:42:39.196+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:42:39.212+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:42:39.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:42:39.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:42:39.232+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:42:39.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.631 seconds
[2025-01-14T00:43:09.327+0000] {processor.py:186} INFO - Started process (PID=40973) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:43:09.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:43:09.331+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:43:09.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:43:11.748+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:43:11.765+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:43:11.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:43:11.784+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:43:11.783+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:43:11.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.480 seconds
[2025-01-14T00:43:41.976+0000] {processor.py:186} INFO - Started process (PID=41042) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:43:41.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:43:41.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:43:41.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:43:44.377+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:43:44.394+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:43:44.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:43:44.413+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:43:44.412+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:43:44.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.459 seconds
[2025-01-14T00:44:15.215+0000] {processor.py:186} INFO - Started process (PID=41107) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:44:15.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:44:15.220+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:44:15.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:44:17.668+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:44:17.689+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:44:17.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:44:17.710+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:44:17.709+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:44:17.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.517 seconds
[2025-01-14T00:44:47.835+0000] {processor.py:186} INFO - Started process (PID=41175) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:44:47.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:44:47.840+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:44:47.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:44:50.272+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:44:50.287+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:44:50.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:44:50.308+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:44:50.308+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:44:50.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.496 seconds
[2025-01-14T00:45:20.399+0000] {processor.py:186} INFO - Started process (PID=41242) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:45:20.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:45:20.402+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:45:20.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:45:22.810+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:45:22.826+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:45:22.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:45:22.848+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:45:22.848+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:45:22.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.470 seconds
[2025-01-14T00:45:53.216+0000] {processor.py:186} INFO - Started process (PID=41309) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:45:53.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:45:53.220+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:45:53.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:45:55.721+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:45:55.737+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:45:55.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:45:55.759+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:45:55.758+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:45:55.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.569 seconds
[2025-01-14T00:46:25.858+0000] {processor.py:186} INFO - Started process (PID=41381) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:46:25.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:46:25.863+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:46:25.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:46:28.382+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:46:28.399+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:46:28.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:46:28.420+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:46:28.420+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:46:28.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.582 seconds
[2025-01-14T00:46:59.242+0000] {processor.py:186} INFO - Started process (PID=41458) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:46:59.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:46:59.247+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:46:59.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:47:01.697+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:47:01.714+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:47:01.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:47:01.736+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:47:01.735+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:47:01.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.516 seconds
[2025-01-14T00:47:32.660+0000] {processor.py:186} INFO - Started process (PID=41537) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:47:32.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:47:32.664+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:47:32.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:47:35.033+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:47:35.049+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:47:35.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:47:35.070+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:47:35.070+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:47:35.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T00:48:05.803+0000] {processor.py:186} INFO - Started process (PID=41602) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:48:05.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:48:05.808+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:48:05.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:48:08.214+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:48:08.234+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:48:08.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:48:08.258+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:48:08.258+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:48:08.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.479 seconds
[2025-01-14T00:48:38.989+0000] {processor.py:186} INFO - Started process (PID=41672) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:48:38.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:48:38.993+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:48:38.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:48:41.444+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:48:41.460+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:48:41.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:48:41.479+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:48:41.479+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:48:41.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.513 seconds
[2025-01-14T00:49:11.916+0000] {processor.py:186} INFO - Started process (PID=41738) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:49:11.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:49:11.921+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:49:11.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:49:14.313+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:49:14.330+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:49:14.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:49:14.351+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:49:14.350+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:49:14.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.456 seconds
[2025-01-14T00:49:45.192+0000] {processor.py:186} INFO - Started process (PID=41802) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:49:45.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:49:45.197+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:49:45.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:49:47.658+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:49:47.676+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:49:47.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:49:47.702+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:49:47.702+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:49:47.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.540 seconds
[2025-01-14T00:50:17.860+0000] {processor.py:186} INFO - Started process (PID=41866) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:50:17.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:50:17.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:50:17.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:50:20.397+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:50:20.415+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:50:20.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:50:20.435+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:50:20.435+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:50:20.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.597 seconds
[2025-01-14T00:50:50.726+0000] {processor.py:186} INFO - Started process (PID=41939) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:50:50.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:50:50.730+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:50:50.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:50:53.136+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:50:53.154+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:50:53.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:50:53.175+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:50:53.175+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:50:53.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.474 seconds
[2025-01-14T00:51:23.361+0000] {processor.py:186} INFO - Started process (PID=42006) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:51:23.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:51:23.365+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:51:23.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:51:25.777+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:51:25.794+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:51:25.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:51:25.817+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:51:25.817+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:51:25.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.484 seconds
[2025-01-14T00:51:55.908+0000] {processor.py:186} INFO - Started process (PID=42072) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:51:55.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:51:55.912+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:51:55.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:51:58.345+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:51:58.362+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:51:58.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:51:58.384+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:51:58.384+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:51:58.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.501 seconds
[2025-01-14T00:52:29.257+0000] {processor.py:186} INFO - Started process (PID=42139) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:52:29.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:52:29.261+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:52:29.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:52:31.779+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:52:31.795+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:52:31.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:52:31.817+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:52:31.817+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:52:31.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.583 seconds
[2025-01-14T00:53:02.240+0000] {processor.py:186} INFO - Started process (PID=42218) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:53:02.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:53:02.244+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:53:02.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:53:04.674+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:53:04.690+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:53:04.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:53:04.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:53:04.710+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:53:04.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.493 seconds
[2025-01-14T00:53:35.027+0000] {processor.py:186} INFO - Started process (PID=42289) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:53:35.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:53:35.032+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:53:35.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:53:37.511+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:53:37.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:53:37.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:53:37.548+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:53:37.548+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:53:37.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.542 seconds
[2025-01-14T00:54:07.666+0000] {processor.py:186} INFO - Started process (PID=42364) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:54:07.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:54:07.671+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:54:07.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:54:10.132+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:54:10.148+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:54:10.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:54:10.169+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:54:10.169+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:54:10.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.526 seconds
[2025-01-14T00:54:40.321+0000] {processor.py:186} INFO - Started process (PID=42439) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:54:40.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:54:40.326+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:54:40.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:54:42.705+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:54:42.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:54:42.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:54:42.742+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:54:42.742+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:54:42.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.441 seconds
[2025-01-14T00:55:13.379+0000] {processor.py:186} INFO - Started process (PID=42503) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:55:13.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:55:13.383+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:55:13.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:55:15.760+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:55:15.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:55:15.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:55:15.798+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:55:15.798+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:55:15.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.440 seconds
[2025-01-14T00:55:46.315+0000] {processor.py:186} INFO - Started process (PID=42567) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:55:46.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:55:46.319+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:55:46.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:55:48.676+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:55:48.690+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:55:48.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:55:48.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:55:48.711+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:55:48.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.416 seconds
[2025-01-14T00:56:19.173+0000] {processor.py:186} INFO - Started process (PID=42631) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:56:19.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:56:19.177+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:56:19.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:56:21.527+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:56:21.548+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:56:21.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:56:21.571+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:56:21.571+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:56:21.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.422 seconds
[2025-01-14T00:56:51.921+0000] {processor.py:186} INFO - Started process (PID=42695) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:56:51.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:56:51.926+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:56:51.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:56:54.314+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:56:54.329+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:56:54.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:56:54.349+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:56:54.348+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:56:54.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.448 seconds
[2025-01-14T00:57:24.849+0000] {processor.py:186} INFO - Started process (PID=42761) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:57:24.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:57:24.853+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:57:24.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:57:27.302+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:57:27.318+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:57:27.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:57:27.337+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:57:27.337+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:57:27.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.511 seconds
[2025-01-14T00:57:58.241+0000] {processor.py:186} INFO - Started process (PID=42834) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:57:58.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:57:58.245+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:57:58.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:58:00.656+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:58:00.671+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:58:00.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:58:00.690+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:58:00.690+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:58:00.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.470 seconds
[2025-01-14T00:58:30.804+0000] {processor.py:186} INFO - Started process (PID=42901) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:58:30.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:58:30.807+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:58:30.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:58:33.186+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:58:33.204+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:58:33.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:58:33.223+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:58:33.223+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:58:33.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.440 seconds
[2025-01-14T00:59:03.690+0000] {processor.py:186} INFO - Started process (PID=42965) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:59:03.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:59:03.694+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:59:03.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:59:06.127+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:59:06.145+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:59:06.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:59:06.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:59:06.165+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:59:06.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.496 seconds
[2025-01-14T00:59:36.444+0000] {processor.py:186} INFO - Started process (PID=43037) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:59:36.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T00:59:36.447+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:59:36.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:59:39.019+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T00:59:39.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:59:39.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T00:59:39.055+0000] {logging_mixin.py:190} INFO - [2025-01-14T00:59:39.055+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T00:59:39.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.632 seconds
[2025-01-14T01:00:09.483+0000] {processor.py:186} INFO - Started process (PID=43124) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:00:09.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:00:09.488+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:00:09.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:00:11.926+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:00:11.942+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:00:11.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:00:11.960+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:00:11.960+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:00:11.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.499 seconds
[2025-01-14T01:00:42.554+0000] {processor.py:186} INFO - Started process (PID=43199) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:00:42.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:00:42.558+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:00:42.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:00:44.941+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:00:44.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:00:44.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:00:44.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:00:44.981+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:00:44.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.449 seconds
[2025-01-14T01:01:15.103+0000] {processor.py:186} INFO - Started process (PID=43266) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:01:15.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:01:15.108+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:01:15.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:01:17.479+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:01:17.495+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:01:17.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:01:17.513+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:01:17.513+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:01:17.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.432 seconds
[2025-01-14T01:01:47.641+0000] {processor.py:186} INFO - Started process (PID=43331) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:01:47.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:01:47.646+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:01:47.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:01:50.042+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:01:50.059+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:01:50.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:01:50.079+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:01:50.078+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:01:50.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.459 seconds
[2025-01-14T01:02:20.789+0000] {processor.py:186} INFO - Started process (PID=43395) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:02:20.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:02:20.793+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:02:20.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:02:23.165+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:02:23.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:02:23.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:02:23.200+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:02:23.199+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:02:23.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.433 seconds
[2025-01-14T01:02:54.106+0000] {processor.py:186} INFO - Started process (PID=43461) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:02:54.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:02:54.111+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:02:54.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:02:56.467+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:02:56.482+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:02:56.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:02:56.504+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:02:56.503+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:02:56.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.418 seconds
[2025-01-14T01:03:26.957+0000] {processor.py:186} INFO - Started process (PID=43525) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:03:26.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:03:26.961+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:03:26.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:03:29.332+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:03:29.348+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:03:29.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:03:29.368+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:03:29.368+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:03:29.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.433 seconds
[2025-01-14T01:04:00.024+0000] {processor.py:186} INFO - Started process (PID=43589) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:04:00.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:04:00.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:04:00.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:04:02.418+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:04:02.435+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:04:02.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:04:02.455+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:04:02.454+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:04:02.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.455 seconds
[2025-01-14T01:04:32.615+0000] {processor.py:186} INFO - Started process (PID=43658) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:04:32.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:04:32.619+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:04:32.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:04:35.036+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:04:35.051+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:04:35.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:04:35.071+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:04:35.071+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:04:35.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.478 seconds
[2025-01-14T01:05:05.214+0000] {processor.py:186} INFO - Started process (PID=43728) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:05:05.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:05:05.218+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:05:05.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:05:07.607+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:05:07.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:05:07.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:05:07.642+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:05:07.642+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:05:07.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.450 seconds
[2025-01-14T01:05:38.596+0000] {processor.py:186} INFO - Started process (PID=43796) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:05:38.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:05:38.600+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:05:38.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:05:41.062+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:05:41.079+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:05:41.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:05:41.100+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:05:41.100+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:05:41.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.531 seconds
[2025-01-14T01:06:11.657+0000] {processor.py:186} INFO - Started process (PID=43874) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:06:11.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:06:11.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:06:11.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:06:14.116+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:06:14.133+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:06:14.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:06:14.152+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:06:14.152+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:06:14.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.518 seconds
[2025-01-14T01:06:44.382+0000] {processor.py:186} INFO - Started process (PID=43951) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:06:44.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:06:44.386+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:06:44.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:06:46.793+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:06:46.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:06:46.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:06:46.831+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:06:46.831+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:06:46.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.473 seconds
[2025-01-14T01:07:17.631+0000] {processor.py:186} INFO - Started process (PID=44020) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:07:17.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:07:17.635+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:07:17.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:07:20.069+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:07:20.084+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:07:20.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:07:20.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:07:20.105+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:07:20.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.496 seconds
[2025-01-14T01:07:50.819+0000] {processor.py:186} INFO - Started process (PID=44096) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:07:50.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:07:50.823+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:07:50.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:07:53.204+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:07:53.221+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:07:53.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:07:53.241+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:07:53.241+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:07:53.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.444 seconds
[2025-01-14T01:08:23.672+0000] {processor.py:186} INFO - Started process (PID=44161) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:08:23.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:08:23.676+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:08:23.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:08:26.036+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:08:26.053+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:08:26.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:08:26.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:08:26.075+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:08:26.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.425 seconds
[2025-01-14T01:08:56.207+0000] {processor.py:186} INFO - Started process (PID=44225) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:08:56.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:08:56.211+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:08:56.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:08:58.557+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:08:58.574+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:08:58.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:08:58.594+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:08:58.593+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:08:58.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.407 seconds
[2025-01-14T01:09:29.034+0000] {processor.py:186} INFO - Started process (PID=44289) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:09:29.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:09:29.039+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:09:29.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:09:31.384+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:09:31.400+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:09:31.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:09:31.421+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:09:31.421+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:09:31.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.411 seconds
[2025-01-14T01:10:01.812+0000] {processor.py:186} INFO - Started process (PID=44353) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:10:01.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:10:01.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:10:01.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:10:04.189+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:10:04.206+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:10:04.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:10:04.227+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:10:04.227+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:10:04.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.438 seconds
[2025-01-14T01:10:34.505+0000] {processor.py:186} INFO - Started process (PID=44417) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:10:34.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:10:34.509+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:10:34.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:10:36.888+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:10:36.905+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:10:36.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:10:36.926+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:10:36.926+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:10:36.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.445 seconds
[2025-01-14T01:11:07.346+0000] {processor.py:186} INFO - Started process (PID=44483) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:11:07.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:11:07.350+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:11:07.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:11:09.745+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:11:09.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:11:09.766+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:11:09.789+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:11:09.789+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:11:09.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.466 seconds
[2025-01-14T01:11:40.474+0000] {processor.py:186} INFO - Started process (PID=44559) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:11:40.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:11:40.479+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:11:40.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:11:42.883+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:11:42.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:11:42.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:11:42.918+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:11:42.918+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:11:42.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.466 seconds
[2025-01-14T01:12:13.812+0000] {processor.py:186} INFO - Started process (PID=44628) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:12:13.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:12:13.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:12:13.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:12:16.212+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:12:16.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:12:16.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:12:16.248+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:12:16.248+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:12:16.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.459 seconds
[2025-01-14T01:12:46.352+0000] {processor.py:186} INFO - Started process (PID=44695) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:12:46.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:12:46.356+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:12:46.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:12:48.761+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:12:48.784+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:12:48.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:12:48.805+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:12:48.805+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:12:48.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.477 seconds
[2025-01-14T01:13:19.106+0000] {processor.py:186} INFO - Started process (PID=44763) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:13:19.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:13:19.110+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:13:19.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:13:21.535+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:13:21.552+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:13:21.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:13:21.572+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:13:21.572+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:13:21.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.490 seconds
[2025-01-14T01:13:51.673+0000] {processor.py:186} INFO - Started process (PID=44841) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:13:51.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:13:51.678+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:13:51.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:13:54.153+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:13:54.171+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:13:54.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:13:54.194+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:13:54.193+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:13:54.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.546 seconds
[2025-01-14T01:14:25.238+0000] {processor.py:186} INFO - Started process (PID=44922) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:14:25.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:14:25.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:14:25.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:14:27.633+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:14:27.648+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:14:27.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:14:27.669+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:14:27.668+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:14:27.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.453 seconds
[2025-01-14T01:14:57.957+0000] {processor.py:186} INFO - Started process (PID=44988) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:14:57.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:14:57.961+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:14:57.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:15:00.319+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:15:00.334+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:15:00.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:15:00.353+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:15:00.353+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:15:00.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.417 seconds
[2025-01-14T01:15:31.137+0000] {processor.py:186} INFO - Started process (PID=45053) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:15:31.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:15:31.141+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:15:31.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:15:33.506+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:15:33.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:15:33.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:15:33.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:15:33.543+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:15:33.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.430 seconds
[2025-01-14T01:16:04.040+0000] {processor.py:186} INFO - Started process (PID=45117) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:16:04.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:16:04.045+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:16:04.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:16:06.395+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:16:06.411+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:16:06.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:16:06.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:16:06.432+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:16:06.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.414 seconds
[2025-01-14T01:16:36.927+0000] {processor.py:186} INFO - Started process (PID=45181) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:16:36.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:16:36.932+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:16:36.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:16:39.279+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:16:39.294+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:16:39.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:16:39.315+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:16:39.315+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:16:39.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.411 seconds
[2025-01-14T01:17:09.538+0000] {processor.py:186} INFO - Started process (PID=45244) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:17:09.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:17:09.542+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:17:09.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:17:11.934+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:17:11.951+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:17:11.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:17:11.974+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:17:11.974+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:17:11.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.465 seconds
[2025-01-14T01:17:42.134+0000] {processor.py:186} INFO - Started process (PID=45317) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:17:42.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:17:42.137+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:17:42.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:17:44.526+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:17:44.541+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:17:44.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:17:44.564+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:17:44.564+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:17:44.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.452 seconds
[2025-01-14T01:18:14.830+0000] {processor.py:186} INFO - Started process (PID=45383) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:18:14.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:18:14.834+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:18:14.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:18:17.220+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:18:17.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:18:17.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:18:17.257+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:18:17.257+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:18:17.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.448 seconds
[2025-01-14T01:18:47.371+0000] {processor.py:186} INFO - Started process (PID=45452) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:18:47.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:18:47.376+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:18:47.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:18:49.746+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:18:49.762+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:18:49.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:18:49.783+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:18:49.783+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:18:49.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.433 seconds
[2025-01-14T01:19:20.729+0000] {processor.py:186} INFO - Started process (PID=45520) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:19:20.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:19:20.733+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:19:20.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:19:23.113+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:19:23.129+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:19:23.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:19:23.151+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:19:23.150+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:19:23.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.446 seconds
[2025-01-14T01:19:53.367+0000] {processor.py:186} INFO - Started process (PID=45587) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:19:53.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:19:53.370+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:19:53.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:19:55.829+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:19:55.844+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:19:55.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:19:55.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:19:55.865+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:19:55.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.522 seconds
[2025-01-14T01:20:25.955+0000] {processor.py:186} INFO - Started process (PID=45659) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:20:25.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:20:25.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:20:25.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:20:28.408+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:20:28.427+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:20:28.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:20:28.451+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:20:28.450+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:20:28.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.523 seconds
[2025-01-14T01:20:58.817+0000] {processor.py:186} INFO - Started process (PID=45727) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:20:58.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:20:58.822+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:20:58.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:21:01.227+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:21:01.244+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:21:01.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:21:01.266+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:21:01.266+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:21:01.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.475 seconds
[2025-01-14T01:21:31.739+0000] {processor.py:186} INFO - Started process (PID=45792) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:21:31.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:21:31.744+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:21:31.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:21:34.376+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:21:34.391+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:21:34.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:21:34.412+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:21:34.412+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:21:34.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.695 seconds
[2025-01-14T01:22:05.277+0000] {processor.py:186} INFO - Started process (PID=45879) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:22:05.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:22:05.282+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:22:05.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:22:07.779+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:22:07.794+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:22:07.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:22:07.815+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:22:07.815+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:22:07.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.560 seconds
[2025-01-14T01:22:38.656+0000] {processor.py:186} INFO - Started process (PID=45944) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:22:38.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:22:38.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:22:38.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:22:41.186+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:22:41.208+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:22:41.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:22:41.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:22:41.228+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:22:41.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.594 seconds
[2025-01-14T01:23:12.072+0000] {processor.py:186} INFO - Started process (PID=46014) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:23:12.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:23:12.076+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:23:12.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:23:14.616+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:23:14.631+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:23:14.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:23:14.650+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:23:14.650+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:23:14.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.600 seconds
[2025-01-14T01:23:44.961+0000] {processor.py:186} INFO - Started process (PID=46080) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:23:44.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:23:44.964+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:23:44.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:23:47.508+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:23:47.523+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:23:47.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:23:47.542+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:23:47.542+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:23:47.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.603 seconds
[2025-01-14T01:24:17.660+0000] {processor.py:186} INFO - Started process (PID=46144) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:24:17.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:24:17.663+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:24:17.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:24:20.238+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:24:20.255+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:24:20.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:24:20.275+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:24:20.275+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:24:20.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.638 seconds
[2025-01-14T01:24:50.732+0000] {processor.py:186} INFO - Started process (PID=46208) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:24:50.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:24:50.736+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:24:50.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:24:53.321+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:24:53.338+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:24:53.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:24:53.356+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:24:53.356+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:24:53.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.644 seconds
[2025-01-14T01:25:23.821+0000] {processor.py:186} INFO - Started process (PID=46283) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:25:23.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:25:23.826+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:25:23.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:25:26.419+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:25:26.437+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:25:26.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:25:26.458+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:25:26.457+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:25:26.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.656 seconds
[2025-01-14T01:25:56.656+0000] {processor.py:186} INFO - Started process (PID=46351) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:25:56.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:25:56.661+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:25:56.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:25:59.238+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:25:59.255+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:25:59.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:25:59.277+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:25:59.276+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:25:59.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.640 seconds
[2025-01-14T01:26:29.603+0000] {processor.py:186} INFO - Started process (PID=46422) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:26:29.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:26:29.608+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:26:29.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:26:32.140+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:26:32.161+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:26:32.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:26:32.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:26:32.181+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:26:32.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.600 seconds
[2025-01-14T01:27:02.459+0000] {processor.py:186} INFO - Started process (PID=46489) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:27:02.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:27:02.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:27:02.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:27:05.039+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:27:05.056+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:27:05.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:27:05.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:27:05.075+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:27:05.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.638 seconds
[2025-01-14T01:27:35.805+0000] {processor.py:186} INFO - Started process (PID=46557) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:27:35.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:27:35.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:27:35.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:27:38.198+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:27:38.214+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:27:38.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:27:38.233+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:27:38.233+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:27:38.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.448 seconds
[2025-01-14T01:28:09.079+0000] {processor.py:186} INFO - Started process (PID=46621) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:28:09.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:28:09.083+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:28:09.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:28:11.467+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:28:11.485+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:28:11.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:28:11.503+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:28:11.503+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:28:11.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.446 seconds
[2025-01-14T01:28:42.469+0000] {processor.py:186} INFO - Started process (PID=46691) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:28:42.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:28:42.474+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:28:42.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:28:44.883+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:28:44.901+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:28:44.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:28:44.920+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:28:44.920+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:28:44.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.473 seconds
[2025-01-14T01:29:15.712+0000] {processor.py:186} INFO - Started process (PID=46755) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:29:15.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:29:15.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:29:15.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:29:18.142+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:29:18.157+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:29:18.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:29:18.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:29:18.178+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:29:18.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.491 seconds
[2025-01-14T01:29:48.596+0000] {processor.py:186} INFO - Started process (PID=46819) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:29:48.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:29:48.600+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:29:48.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:29:51.100+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:29:51.123+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:29:51.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:29:51.146+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:29:51.145+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:29:51.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.571 seconds
[2025-01-14T01:30:21.257+0000] {processor.py:186} INFO - Started process (PID=46899) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:30:21.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:30:21.262+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:30:21.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:30:23.720+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:30:23.738+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:30:23.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:30:23.758+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:30:23.758+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:30:23.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.523 seconds
[2025-01-14T01:30:54.468+0000] {processor.py:186} INFO - Started process (PID=46973) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:30:54.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:30:54.474+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:30:54.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:30:56.864+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:30:56.883+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:30:56.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:30:56.905+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:30:56.905+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:30:56.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.460 seconds
[2025-01-14T01:31:27.763+0000] {processor.py:186} INFO - Started process (PID=47037) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:31:27.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:31:27.767+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:31:27.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:31:30.247+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:31:30.265+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:31:30.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:31:30.284+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:31:30.284+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:31:30.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.543 seconds
[2025-01-14T01:32:01.098+0000] {processor.py:186} INFO - Started process (PID=47107) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:32:01.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:32:01.103+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:32:01.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:32:03.608+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:32:03.626+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:32:03.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:32:03.647+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:32:03.647+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:32:03.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.570 seconds
[2025-01-14T01:32:34.040+0000] {processor.py:186} INFO - Started process (PID=47182) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:32:34.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:32:34.043+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:32:34.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:32:36.472+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:32:36.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:32:36.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:32:36.517+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:32:36.517+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:32:36.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.503 seconds
[2025-01-14T01:33:06.735+0000] {processor.py:186} INFO - Started process (PID=47247) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:33:06.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:33:06.739+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:33:06.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:33:09.215+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:33:09.237+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:33:09.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:33:09.256+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:33:09.256+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:33:09.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.545 seconds
[2025-01-14T01:33:39.441+0000] {processor.py:186} INFO - Started process (PID=47322) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:33:39.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:33:39.445+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:33:39.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:33:41.849+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:33:41.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:33:41.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:33:41.885+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:33:41.884+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:33:41.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.467 seconds
[2025-01-14T01:34:12.319+0000] {processor.py:186} INFO - Started process (PID=47388) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:34:12.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:34:12.323+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:34:12.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:34:14.698+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:34:14.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:34:14.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:34:14.733+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:34:14.733+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:34:14.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T01:34:45.715+0000] {processor.py:186} INFO - Started process (PID=47458) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:34:45.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:34:45.718+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:34:45.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:34:48.092+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:34:48.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:34:48.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:34:48.127+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:34:48.127+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:34:48.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.433 seconds
[2025-01-14T01:35:18.316+0000] {processor.py:186} INFO - Started process (PID=47522) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:35:18.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:35:18.320+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:35:18.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:35:20.695+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:35:20.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:35:20.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:35:20.729+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:35:20.729+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:35:20.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.435 seconds
[2025-01-14T01:35:50.891+0000] {processor.py:186} INFO - Started process (PID=47585) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:35:50.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:35:50.895+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:35:50.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:35:53.271+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:35:53.286+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:35:53.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:35:53.305+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:35:53.305+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:35:53.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.437 seconds
[2025-01-14T01:36:23.396+0000] {processor.py:186} INFO - Started process (PID=47649) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:36:23.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:36:23.401+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:36:23.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:36:25.768+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:36:25.787+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:36:25.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:36:25.806+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:36:25.806+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:36:25.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.431 seconds
[2025-01-14T01:36:55.923+0000] {processor.py:186} INFO - Started process (PID=47713) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:36:55.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:36:55.927+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:36:55.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:36:58.300+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:36:58.317+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:36:58.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:36:58.337+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:36:58.336+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:36:58.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T01:37:28.762+0000] {processor.py:186} INFO - Started process (PID=47777) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:37:28.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:37:28.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:37:28.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:37:31.282+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:37:31.299+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:37:31.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:37:31.317+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:37:31.317+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:37:31.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.578 seconds
[2025-01-14T01:38:01.826+0000] {processor.py:186} INFO - Started process (PID=47841) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:38:01.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:38:01.831+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:38:01.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:38:04.321+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:38:04.341+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:38:04.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:38:04.361+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:38:04.361+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:38:04.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.559 seconds
[2025-01-14T01:38:34.713+0000] {processor.py:186} INFO - Started process (PID=47912) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:38:34.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:38:34.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:38:34.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:38:37.172+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:38:37.189+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:38:37.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:38:37.208+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:38:37.208+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:38:37.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.518 seconds
[2025-01-14T01:39:08.246+0000] {processor.py:186} INFO - Started process (PID=47995) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:39:08.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:39:08.249+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:39:08.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:39:10.779+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:39:10.795+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:39:10.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:39:10.813+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:39:10.813+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:39:10.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.591 seconds
[2025-01-14T01:39:41.282+0000] {processor.py:186} INFO - Started process (PID=48070) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:39:41.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:39:41.286+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:39:41.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:39:43.757+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:39:43.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:39:43.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:39:43.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:39:43.796+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:39:43.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.540 seconds
[2025-01-14T01:40:13.963+0000] {processor.py:186} INFO - Started process (PID=48146) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:40:13.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:40:13.968+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:40:13.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:40:16.441+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:40:16.457+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:40:16.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:40:16.476+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:40:16.476+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:40:16.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.534 seconds
[2025-01-14T01:40:47.032+0000] {processor.py:186} INFO - Started process (PID=48221) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:40:47.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:40:47.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:40:47.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:40:49.402+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:40:49.417+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:40:49.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:40:49.437+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:40:49.437+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:40:49.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.428 seconds
[2025-01-14T01:41:20.375+0000] {processor.py:186} INFO - Started process (PID=48287) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:41:20.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:41:20.380+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:41:20.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:41:22.779+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:41:22.797+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:41:22.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:41:22.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:41:22.816+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:41:22.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.465 seconds
[2025-01-14T01:41:53.164+0000] {processor.py:186} INFO - Started process (PID=48351) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:41:53.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:41:53.168+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:41:53.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:41:55.545+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:41:55.561+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:41:55.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:41:55.581+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:41:55.581+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:41:55.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.438 seconds
[2025-01-14T01:42:26.098+0000] {processor.py:186} INFO - Started process (PID=48416) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:42:26.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:42:26.102+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:42:26.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:42:28.507+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:42:28.524+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:42:28.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:42:28.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:42:28.542+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:42:28.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.466 seconds
[2025-01-14T01:42:58.753+0000] {processor.py:186} INFO - Started process (PID=48480) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:42:58.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:42:58.757+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:42:58.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:43:01.127+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:43:01.144+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:43:01.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:43:01.164+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:43:01.164+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:43:01.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T01:43:31.620+0000] {processor.py:186} INFO - Started process (PID=48544) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:43:31.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:43:31.624+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:43:31.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:43:34.015+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:43:34.031+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:43:34.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:43:34.055+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:43:34.055+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:43:34.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.458 seconds
[2025-01-14T01:44:04.609+0000] {processor.py:186} INFO - Started process (PID=48608) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:44:04.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:44:04.614+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:44:04.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:44:06.993+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:44:07.009+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:44:07.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:44:07.029+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:44:07.029+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:44:07.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.442 seconds
[2025-01-14T01:44:37.576+0000] {processor.py:186} INFO - Started process (PID=48672) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:44:37.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:44:37.580+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:44:37.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:44:40.009+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:44:40.025+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:44:40.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:44:40.046+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:44:40.046+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:44:40.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.491 seconds
[2025-01-14T01:45:10.675+0000] {processor.py:186} INFO - Started process (PID=48740) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:45:10.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:45:10.680+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:45:10.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:45:13.030+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:45:13.046+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:45:13.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:45:13.065+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:45:13.065+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:45:13.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.421 seconds
[2025-01-14T01:45:43.857+0000] {processor.py:186} INFO - Started process (PID=48808) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:45:43.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:45:43.861+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:45:43.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:45:46.296+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:45:46.313+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:45:46.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:45:46.333+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:45:46.333+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:45:46.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.499 seconds
[2025-01-14T01:46:16.451+0000] {processor.py:186} INFO - Started process (PID=48876) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:46:16.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:46:16.455+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:46:16.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:46:18.893+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:46:18.911+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:46:18.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:46:18.939+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:46:18.939+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:46:18.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.514 seconds
[2025-01-14T01:46:49.964+0000] {processor.py:186} INFO - Started process (PID=48945) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:46:49.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:46:49.969+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:46:49.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:46:52.607+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:46:52.625+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:46:52.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:46:52.649+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:46:52.649+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:46:52.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.708 seconds
[2025-01-14T01:47:23.428+0000] {processor.py:186} INFO - Started process (PID=49031) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:47:23.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:47:23.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:47:23.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:47:25.919+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:47:25.936+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:47:25.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:47:25.957+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:47:25.956+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:47:25.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.554 seconds
[2025-01-14T01:47:56.574+0000] {processor.py:186} INFO - Started process (PID=49099) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:47:56.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:47:56.578+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:47:56.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:47:59.048+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:47:59.063+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:47:59.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:47:59.086+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:47:59.085+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:47:59.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.536 seconds
[2025-01-14T01:48:29.686+0000] {processor.py:186} INFO - Started process (PID=49177) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:48:29.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:48:29.690+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:48:29.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:48:32.091+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:48:32.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:48:32.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:48:32.128+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:48:32.128+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:48:32.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.466 seconds
[2025-01-14T01:49:02.269+0000] {processor.py:186} INFO - Started process (PID=49242) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:49:02.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:49:02.274+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:49:02.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:49:04.678+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:49:04.692+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:49:04.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:49:04.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:49:04.713+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:49:04.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.466 seconds
[2025-01-14T01:49:35.176+0000] {processor.py:186} INFO - Started process (PID=49307) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:49:35.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:49:35.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:49:35.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:49:37.555+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:49:37.571+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:49:37.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:49:37.593+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:49:37.593+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:49:37.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.439 seconds
[2025-01-14T01:50:08.034+0000] {processor.py:186} INFO - Started process (PID=49371) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:50:08.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:50:08.038+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:50:08.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:50:10.413+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:50:10.429+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:50:10.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:50:10.454+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:50:10.453+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:50:10.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.442 seconds
[2025-01-14T01:50:41.061+0000] {processor.py:186} INFO - Started process (PID=49435) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:50:41.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:50:41.066+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:50:41.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:50:43.497+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:50:43.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:50:43.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:50:43.532+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:50:43.531+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:50:43.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.493 seconds
[2025-01-14T01:51:13.639+0000] {processor.py:186} INFO - Started process (PID=49504) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:51:13.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:51:13.644+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:51:13.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:51:16.043+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:51:16.060+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:51:16.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:51:16.081+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:51:16.081+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:51:16.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.464 seconds
[2025-01-14T01:51:46.291+0000] {processor.py:186} INFO - Started process (PID=49574) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:51:46.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:51:46.296+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:51:46.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:51:48.713+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:51:48.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:51:48.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:51:48.752+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:51:48.752+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:51:48.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.484 seconds
[2025-01-14T01:52:19.564+0000] {processor.py:186} INFO - Started process (PID=49639) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:52:19.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:52:19.568+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:52:19.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:52:21.990+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:52:22.006+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:52:22.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:52:22.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:52:22.028+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:52:22.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.486 seconds
[2025-01-14T01:52:52.168+0000] {processor.py:186} INFO - Started process (PID=49705) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:52:52.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:52:52.172+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:52:52.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:52:54.614+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:52:54.631+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:52:54.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:52:54.652+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:52:54.651+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:52:54.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.512 seconds
[2025-01-14T01:53:24.758+0000] {processor.py:186} INFO - Started process (PID=49773) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:53:24.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:53:24.762+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:53:24.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:53:27.292+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:53:27.313+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:53:27.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:53:27.338+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:53:27.338+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:53:27.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.607 seconds
[2025-01-14T01:53:57.697+0000] {processor.py:186} INFO - Started process (PID=49847) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:53:57.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:53:57.701+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:53:57.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:54:00.223+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:54:00.239+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:54:00.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:54:00.259+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:54:00.259+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:54:00.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.584 seconds
[2025-01-14T01:54:30.837+0000] {processor.py:186} INFO - Started process (PID=49928) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:54:30.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:54:30.841+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:54:30.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:54:33.195+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:54:33.210+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:54:33.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:54:33.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:54:33.232+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:54:33.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.417 seconds
[2025-01-14T01:55:03.383+0000] {processor.py:186} INFO - Started process (PID=49992) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:55:03.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:55:03.387+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:55:03.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:55:05.818+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:55:05.835+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:55:05.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:55:05.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:55:05.857+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:55:05.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.505 seconds
[2025-01-14T01:55:35.949+0000] {processor.py:186} INFO - Started process (PID=50069) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:55:35.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:55:35.954+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:55:35.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:55:38.329+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:55:38.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:55:38.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:55:38.367+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:55:38.366+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:55:38.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.440 seconds
[2025-01-14T01:56:09.389+0000] {processor.py:186} INFO - Started process (PID=50133) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:56:09.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:56:09.394+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:56:09.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:56:11.724+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:56:11.741+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:56:11.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:56:11.761+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:56:11.761+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:56:11.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.394 seconds
[2025-01-14T01:56:42.794+0000] {processor.py:186} INFO - Started process (PID=50197) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:56:42.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:56:42.798+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:56:42.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:56:45.191+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:56:45.212+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:56:45.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:56:45.233+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:56:45.232+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:56:45.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.459 seconds
[2025-01-14T01:57:16.110+0000] {processor.py:186} INFO - Started process (PID=50267) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:57:16.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:57:16.114+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:57:16.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:57:18.525+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:57:18.546+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:57:18.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:57:18.570+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:57:18.569+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:57:18.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.652 seconds
[2025-01-14T01:57:49.503+0000] {processor.py:186} INFO - Started process (PID=50331) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:57:49.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:57:49.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:57:49.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:57:52.023+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:57:52.043+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:57:52.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:57:52.065+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:57:52.065+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:57:52.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.589 seconds
[2025-01-14T01:58:22.225+0000] {processor.py:186} INFO - Started process (PID=50398) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:58:22.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:58:22.229+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:58:22.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:58:24.709+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:58:24.726+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:58:24.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:58:24.746+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:58:24.745+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:58:24.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.540 seconds
[2025-01-14T01:58:54.989+0000] {processor.py:186} INFO - Started process (PID=50467) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:58:54.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:58:54.993+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:58:54.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:58:57.448+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:58:57.473+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:58:57.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:58:57.493+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:58:57.493+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:58:57.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.529 seconds
[2025-01-14T01:59:28.000+0000] {processor.py:186} INFO - Started process (PID=50537) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:59:28.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T01:59:28.005+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:59:28.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:59:30.463+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T01:59:30.484+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:59:30.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T01:59:30.503+0000] {logging_mixin.py:190} INFO - [2025-01-14T01:59:30.503+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T01:59:30.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.527 seconds
[2025-01-14T02:00:00.606+0000] {processor.py:186} INFO - Started process (PID=50604) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:00:00.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:00:00.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:00:00.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:00:03.322+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:00:03.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:00:03.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:00:03.366+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:00:03.366+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:00:03.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.783 seconds
[2025-01-14T02:00:33.582+0000] {processor.py:186} INFO - Started process (PID=50681) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:00:33.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:00:33.587+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:00:33.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:00:36.133+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:00:36.149+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:00:36.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:00:36.170+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:00:36.170+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:00:36.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.609 seconds
[2025-01-14T02:01:07.065+0000] {processor.py:186} INFO - Started process (PID=50759) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:01:07.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:01:07.070+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:01:07.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:01:09.542+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:01:09.559+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:01:09.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:01:09.578+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:01:09.578+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:01:09.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.536 seconds
[2025-01-14T02:01:39.806+0000] {processor.py:186} INFO - Started process (PID=50823) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:01:39.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:01:39.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:01:39.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:01:42.321+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:01:42.339+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:01:42.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:01:42.359+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:01:42.359+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:01:42.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.575 seconds
[2025-01-14T02:02:13.264+0000] {processor.py:186} INFO - Started process (PID=50900) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:02:13.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:02:13.269+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:02:13.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:02:15.656+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:02:15.670+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:02:15.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:02:15.690+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:02:15.690+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:02:15.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.446 seconds
[2025-01-14T02:02:46.244+0000] {processor.py:186} INFO - Started process (PID=50970) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:02:46.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:02:46.249+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:02:46.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:02:48.580+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:02:48.596+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:02:48.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:02:48.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:02:48.615+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:02:48.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.395 seconds
[2025-01-14T02:03:18.878+0000] {processor.py:186} INFO - Started process (PID=51034) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:03:18.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:03:18.883+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:03:18.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:03:21.255+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:03:21.270+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:03:21.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:03:21.288+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:03:21.288+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:03:21.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.431 seconds
[2025-01-14T02:03:51.527+0000] {processor.py:186} INFO - Started process (PID=51098) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:03:51.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:03:51.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:03:51.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:03:53.893+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:03:53.909+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:03:53.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:03:53.930+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:03:53.930+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:03:53.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.425 seconds
[2025-01-14T02:04:24.790+0000] {processor.py:186} INFO - Started process (PID=51162) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:04:24.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:04:24.794+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:04:24.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:04:27.184+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:04:27.201+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:04:27.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:04:27.221+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:04:27.220+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:04:27.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.453 seconds
[2025-01-14T02:04:58.034+0000] {processor.py:186} INFO - Started process (PID=51225) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:04:58.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:04:58.038+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:04:58.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:05:00.376+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:05:00.391+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:05:00.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:05:00.412+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:05:00.412+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:05:00.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.400 seconds
[2025-01-14T02:05:30.567+0000] {processor.py:186} INFO - Started process (PID=51290) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:05:30.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:05:30.572+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:05:30.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:05:32.974+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:05:32.989+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:05:32.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:05:33.012+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:05:33.012+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:05:33.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.466 seconds
[2025-01-14T02:06:03.236+0000] {processor.py:186} INFO - Started process (PID=51357) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:06:03.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:06:03.240+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:06:03.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:06:05.654+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:06:05.670+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:06:05.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:06:05.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:06:05.693+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:06:05.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.479 seconds
[2025-01-14T02:06:36.258+0000] {processor.py:186} INFO - Started process (PID=51425) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:06:36.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:06:36.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:06:36.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:06:38.644+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:06:38.659+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:06:38.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:06:38.680+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:06:38.680+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:06:38.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.445 seconds
[2025-01-14T02:07:09.688+0000] {processor.py:186} INFO - Started process (PID=51490) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:07:09.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:07:09.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:07:09.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:07:12.032+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:07:12.050+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:07:12.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:07:12.072+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:07:12.072+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:07:12.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.406 seconds
[2025-01-14T02:07:42.237+0000] {processor.py:186} INFO - Started process (PID=51554) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:07:42.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:07:42.241+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:07:42.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:07:44.647+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:07:44.665+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:07:44.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:07:44.687+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:07:44.687+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:07:44.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.475 seconds
[2025-01-14T02:08:15.380+0000] {processor.py:186} INFO - Started process (PID=51621) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:08:15.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:08:15.383+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:08:15.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:08:17.895+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:08:17.917+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:08:17.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:08:17.941+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:08:17.941+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:08:17.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.588 seconds
[2025-01-14T02:08:48.071+0000] {processor.py:186} INFO - Started process (PID=51706) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:08:48.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:08:48.074+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:08:48.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:08:50.572+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:08:50.587+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:08:50.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:08:50.608+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:08:50.608+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:08:50.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.561 seconds
[2025-01-14T02:09:21.278+0000] {processor.py:186} INFO - Started process (PID=51785) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:09:21.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:09:21.282+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:09:21.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:09:23.712+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:09:23.728+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:09:23.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:09:23.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:09:23.749+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:09:23.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.495 seconds
[2025-01-14T02:09:54.565+0000] {processor.py:186} INFO - Started process (PID=51863) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:09:54.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:09:54.569+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:09:54.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:09:56.923+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:09:56.938+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:09:56.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:09:56.958+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:09:56.958+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:09:56.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.414 seconds
[2025-01-14T02:10:27.523+0000] {processor.py:186} INFO - Started process (PID=51927) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:10:27.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:10:27.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:10:27.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:10:29.856+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:10:29.871+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:10:29.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:10:29.892+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:10:29.892+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:10:29.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.389 seconds
[2025-01-14T02:11:00.687+0000] {processor.py:186} INFO - Started process (PID=51991) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:11:00.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:11:00.691+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:11:00.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:11:03.029+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:11:03.044+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:11:03.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:11:03.064+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:11:03.064+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:11:03.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.398 seconds
[2025-01-14T02:11:33.498+0000] {processor.py:186} INFO - Started process (PID=52055) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:11:33.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:11:33.501+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:11:33.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:11:35.841+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:11:35.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:11:35.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:11:35.879+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:11:35.879+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:11:35.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.404 seconds
[2025-01-14T02:12:06.532+0000] {processor.py:186} INFO - Started process (PID=52119) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:12:06.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:12:06.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:12:06.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:12:09.099+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:12:09.116+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:12:09.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:12:09.136+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:12:09.136+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:12:09.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.626 seconds
[2025-01-14T02:12:39.487+0000] {processor.py:186} INFO - Started process (PID=52187) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:12:39.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:12:39.491+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:12:39.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:12:42.032+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:12:42.049+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:12:42.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:12:42.073+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:12:42.073+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:12:42.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.612 seconds
[2025-01-14T02:13:12.189+0000] {processor.py:186} INFO - Started process (PID=52255) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:13:12.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:13:12.193+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:13:12.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:13:14.697+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:13:14.712+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:13:14.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:13:14.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:13:14.731+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:13:14.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.564 seconds
[2025-01-14T02:13:44.817+0000] {processor.py:186} INFO - Started process (PID=52320) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:13:44.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:13:44.822+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:13:44.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:13:47.333+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:13:47.348+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:13:47.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:13:47.368+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:13:47.368+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:13:47.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.572 seconds
[2025-01-14T02:14:18.011+0000] {processor.py:186} INFO - Started process (PID=52390) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:14:18.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:14:18.016+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:14:18.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:14:20.512+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:14:20.528+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:14:20.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:14:20.549+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:14:20.549+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:14:20.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.560 seconds
[2025-01-14T02:14:51.327+0000] {processor.py:186} INFO - Started process (PID=52454) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:14:51.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:14:51.331+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:14:51.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:14:53.869+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:14:53.885+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:14:53.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:14:53.905+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:14:53.904+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:14:53.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.600 seconds
[2025-01-14T02:15:24.849+0000] {processor.py:186} INFO - Started process (PID=52522) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:15:24.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:15:24.854+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:15:24.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:15:27.345+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:15:27.361+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:15:27.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:15:27.382+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:15:27.382+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:15:27.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.555 seconds
[2025-01-14T02:15:58.032+0000] {processor.py:186} INFO - Started process (PID=52586) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:15:58.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:15:58.037+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:15:58.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:16:00.569+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:16:00.586+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:16:00.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:16:00.606+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:16:00.606+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:16:00.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.598 seconds
[2025-01-14T02:16:30.762+0000] {processor.py:186} INFO - Started process (PID=52650) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:16:30.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:16:30.767+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:16:30.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:16:33.325+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:16:33.341+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:16:33.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:16:33.363+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:16:33.362+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:16:33.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.622 seconds
[2025-01-14T02:17:03.849+0000] {processor.py:186} INFO - Started process (PID=52719) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:17:03.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:17:03.854+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:17:03.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:17:06.385+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:17:06.404+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:17:06.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:17:06.425+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:17:06.425+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:17:06.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.602 seconds
[2025-01-14T02:17:36.547+0000] {processor.py:186} INFO - Started process (PID=52799) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:17:36.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:17:36.551+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:17:36.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:17:39.118+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:17:39.134+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:17:39.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:17:39.156+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:17:39.156+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:17:39.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.631 seconds
[2025-01-14T02:18:09.455+0000] {processor.py:186} INFO - Started process (PID=52881) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:18:09.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:18:09.459+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:18:09.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:18:11.910+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:18:11.925+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:18:11.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:18:11.945+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:18:11.945+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:18:11.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.511 seconds
[2025-01-14T02:18:42.032+0000] {processor.py:186} INFO - Started process (PID=52951) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:18:42.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:18:42.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:18:42.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:18:44.478+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:18:44.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:18:44.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:18:44.515+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:18:44.515+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:18:44.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.506 seconds
[2025-01-14T02:19:14.859+0000] {processor.py:186} INFO - Started process (PID=53017) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:19:14.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:19:14.863+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:19:14.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:19:17.395+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:19:17.411+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:19:17.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:19:17.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:19:17.431+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:19:17.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.593 seconds
[2025-01-14T02:19:48.463+0000] {processor.py:186} INFO - Started process (PID=53091) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:19:48.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:19:48.467+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:19:48.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:19:50.875+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:19:50.891+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:19:50.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:19:50.913+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:19:50.913+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:19:50.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.473 seconds
[2025-01-14T02:20:21.842+0000] {processor.py:186} INFO - Started process (PID=53156) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:20:21.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:20:21.846+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:20:21.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:20:24.208+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:20:24.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:20:24.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:20:24.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:20:24.242+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:20:24.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.420 seconds
[2025-01-14T02:20:54.414+0000] {processor.py:186} INFO - Started process (PID=53220) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:20:54.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:20:54.419+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:20:54.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:20:56.790+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:20:56.806+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:20:56.805+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:20:56.827+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:20:56.827+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:20:56.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.435 seconds
[2025-01-14T02:21:27.892+0000] {processor.py:186} INFO - Started process (PID=53284) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:21:27.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:21:27.896+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:21:27.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:21:30.315+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:21:30.331+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:21:30.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:21:30.352+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:21:30.352+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:21:30.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.482 seconds
[2025-01-14T02:22:00.509+0000] {processor.py:186} INFO - Started process (PID=53352) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:22:00.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:22:00.513+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:22:00.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:22:02.909+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:22:02.925+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:22:02.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:22:02.947+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:22:02.947+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:22:02.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.460 seconds
[2025-01-14T02:22:33.851+0000] {processor.py:186} INFO - Started process (PID=53416) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:22:33.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:22:33.855+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:22:33.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:22:36.230+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:22:36.245+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:22:36.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:22:36.266+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:22:36.266+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:22:36.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.438 seconds
[2025-01-14T02:23:07.260+0000] {processor.py:186} INFO - Started process (PID=53480) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:23:07.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:23:07.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:23:07.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:23:09.685+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:23:09.700+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:23:09.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:23:09.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:23:09.720+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:23:09.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.483 seconds
[2025-01-14T02:23:40.055+0000] {processor.py:186} INFO - Started process (PID=53544) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:23:40.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:23:40.061+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:23:40.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:23:42.506+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:23:42.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:23:42.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:23:42.544+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:23:42.544+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:23:42.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.514 seconds
[2025-01-14T02:24:12.994+0000] {processor.py:186} INFO - Started process (PID=53609) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:24:12.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:24:12.998+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:24:12.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:24:15.366+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:24:15.381+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:24:15.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:24:15.401+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:24:15.401+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:24:15.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.429 seconds
[2025-01-14T02:24:45.718+0000] {processor.py:186} INFO - Started process (PID=53673) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:24:45.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:24:45.722+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:24:45.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:24:48.184+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:24:48.201+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:24:48.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:24:48.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:24:48.222+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:24:48.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.525 seconds
[2025-01-14T02:25:18.538+0000] {processor.py:186} INFO - Started process (PID=53747) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:25:18.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:25:18.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:25:18.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:25:21.072+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:25:21.092+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:25:21.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:25:21.112+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:25:21.112+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:25:21.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.597 seconds
[2025-01-14T02:25:51.280+0000] {processor.py:186} INFO - Started process (PID=53825) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:25:51.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:25:51.284+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:25:51.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:25:53.771+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:25:53.791+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:25:53.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:25:53.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:25:53.815+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:25:53.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.563 seconds
[2025-01-14T02:26:24.507+0000] {processor.py:186} INFO - Started process (PID=53897) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:26:24.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:26:24.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:26:24.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:26:26.985+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:26:27.007+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:26:27.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:26:27.029+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:26:27.029+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:26:27.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.547 seconds
[2025-01-14T02:26:57.691+0000] {processor.py:186} INFO - Started process (PID=53977) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:26:57.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:26:57.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:26:57.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:27:00.121+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:27:00.137+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:27:00.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:27:00.156+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:27:00.155+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:27:00.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.485 seconds
[2025-01-14T02:27:30.577+0000] {processor.py:186} INFO - Started process (PID=54051) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:27:30.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:27:30.581+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:27:30.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:27:32.982+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:27:32.997+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:27:32.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:27:33.017+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:27:33.017+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:27:33.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.463 seconds
[2025-01-14T02:28:03.762+0000] {processor.py:186} INFO - Started process (PID=54115) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:28:03.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:28:03.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:28:03.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:28:06.196+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:28:06.215+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:28:06.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:28:06.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:28:06.235+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:28:06.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.495 seconds
[2025-01-14T02:28:36.467+0000] {processor.py:186} INFO - Started process (PID=54179) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:28:36.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:28:36.471+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:28:36.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:28:38.871+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:28:38.888+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:28:38.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:28:38.907+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:28:38.907+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:28:38.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.462 seconds
[2025-01-14T02:29:08.992+0000] {processor.py:186} INFO - Started process (PID=54247) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:29:08.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:29:08.996+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:29:08.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:29:11.381+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:29:11.397+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:29:11.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:29:11.418+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:29:11.417+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:29:11.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.447 seconds
[2025-01-14T02:29:41.579+0000] {processor.py:186} INFO - Started process (PID=54311) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:29:41.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:29:41.583+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:29:41.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:29:44.009+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:29:44.026+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:29:44.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:29:44.047+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:29:44.047+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:29:44.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.490 seconds
[2025-01-14T02:30:14.890+0000] {processor.py:186} INFO - Started process (PID=54375) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:30:14.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:30:14.894+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:30:14.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:30:17.264+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:30:17.279+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:30:17.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:30:17.300+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:30:17.300+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:30:17.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.431 seconds
[2025-01-14T02:30:47.501+0000] {processor.py:186} INFO - Started process (PID=54440) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:30:47.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:30:47.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:30:47.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:30:50.421+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:30:50.438+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:30:50.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:30:50.459+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:30:50.458+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:30:50.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.978 seconds
[2025-01-14T02:31:21.349+0000] {processor.py:186} INFO - Started process (PID=54510) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:31:21.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:31:21.353+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:31:21.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:31:23.750+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:31:23.765+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:31:23.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:31:23.787+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:31:23.787+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:31:23.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.460 seconds
[2025-01-14T02:31:54.097+0000] {processor.py:186} INFO - Started process (PID=54574) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:31:54.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:31:54.101+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:31:54.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:31:56.490+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:31:56.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:31:56.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:31:56.530+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:31:56.530+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:31:56.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.457 seconds
[2025-01-14T02:32:27.388+0000] {processor.py:186} INFO - Started process (PID=54641) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:32:27.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:32:27.391+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:32:27.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:32:29.840+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:32:29.858+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:32:29.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:32:29.879+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:32:29.879+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:32:29.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.514 seconds
[2025-01-14T02:32:59.993+0000] {processor.py:186} INFO - Started process (PID=54708) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:32:59.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:32:59.997+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:32:59.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:33:02.480+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:33:02.499+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:33:02.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:33:02.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:33:02.521+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:33:02.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.552 seconds
[2025-01-14T02:33:33.319+0000] {processor.py:186} INFO - Started process (PID=54784) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:33:33.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:33:33.325+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:33:33.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:33:36.182+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:33:36.201+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:33:36.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:33:36.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:33:36.222+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:33:36.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.926 seconds
[2025-01-14T02:34:06.385+0000] {processor.py:186} INFO - Started process (PID=54854) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:34:06.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:34:06.389+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:34:06.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:34:09.034+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:34:09.052+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:34:09.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:34:09.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:34:09.074+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:34:09.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.713 seconds
[2025-01-14T02:34:39.159+0000] {processor.py:186} INFO - Started process (PID=54934) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:34:39.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:34:39.164+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:34:39.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:34:41.709+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:34:41.725+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:34:41.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:34:41.746+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:34:41.746+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:34:41.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.611 seconds
[2025-01-14T02:35:11.924+0000] {processor.py:186} INFO - Started process (PID=55007) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:35:11.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:35:11.928+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:35:11.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:35:14.425+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:35:14.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:35:14.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:35:14.463+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:35:14.462+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:35:14.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.561 seconds
[2025-01-14T02:35:44.658+0000] {processor.py:186} INFO - Started process (PID=55077) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:35:44.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:35:44.663+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:35:44.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:35:47.060+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:35:47.075+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:35:47.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:35:47.095+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:35:47.095+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:35:47.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.459 seconds
[2025-01-14T02:36:17.806+0000] {processor.py:186} INFO - Started process (PID=55141) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:36:17.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:36:17.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:36:17.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:36:20.190+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:36:20.206+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:36:20.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:36:20.226+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:36:20.226+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:36:20.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.443 seconds
[2025-01-14T02:36:50.739+0000] {processor.py:186} INFO - Started process (PID=55210) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:36:50.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:36:50.744+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:36:50.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:36:53.136+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:36:53.153+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:36:53.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:36:53.172+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:36:53.172+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:36:53.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.453 seconds
[2025-01-14T02:37:23.794+0000] {processor.py:186} INFO - Started process (PID=55275) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:37:23.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:37:23.799+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:37:23.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:37:26.270+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:37:26.286+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:37:26.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:37:26.307+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:37:26.307+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:37:26.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.533 seconds
[2025-01-14T02:37:57.099+0000] {processor.py:186} INFO - Started process (PID=55339) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:37:57.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:37:57.103+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:37:57.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:37:59.582+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:37:59.597+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:37:59.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:37:59.619+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:37:59.618+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:37:59.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.542 seconds
[2025-01-14T02:38:30.441+0000] {processor.py:186} INFO - Started process (PID=55404) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:38:30.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:38:30.445+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:38:30.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:38:32.858+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:38:32.874+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:38:32.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:38:32.894+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:38:32.894+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:38:32.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.475 seconds
[2025-01-14T02:39:03.227+0000] {processor.py:186} INFO - Started process (PID=55470) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:39:03.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:39:03.230+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:39:03.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:39:05.694+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:39:05.709+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:39:05.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:39:05.729+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:39:05.729+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:39:05.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.524 seconds
[2025-01-14T02:39:36.540+0000] {processor.py:186} INFO - Started process (PID=55545) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:39:36.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:39:36.545+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:39:36.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:39:39.020+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:39:39.036+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:39:39.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:39:39.058+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:39:39.058+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:39:39.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.541 seconds
[2025-01-14T02:40:09.632+0000] {processor.py:186} INFO - Started process (PID=55612) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:40:09.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:40:09.636+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:40:09.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:40:12.062+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:40:12.078+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:40:12.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:40:12.099+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:40:12.099+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:40:12.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.488 seconds
[2025-01-14T02:40:42.478+0000] {processor.py:186} INFO - Started process (PID=55678) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:40:42.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:40:42.483+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:40:42.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:40:44.862+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:40:44.877+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:40:44.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:40:44.898+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:40:44.898+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:40:44.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.443 seconds
[2025-01-14T02:41:15.329+0000] {processor.py:186} INFO - Started process (PID=55744) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:41:15.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:41:15.333+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:41:15.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:41:17.688+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:41:17.704+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:41:17.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:41:17.724+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:41:17.724+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:41:17.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.416 seconds
[2025-01-14T02:41:48.272+0000] {processor.py:186} INFO - Started process (PID=55808) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:41:48.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:41:48.276+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:41:48.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:41:50.629+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:41:50.645+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:41:50.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:41:50.666+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:41:50.665+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:41:50.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.416 seconds
[2025-01-14T02:42:20.874+0000] {processor.py:186} INFO - Started process (PID=55878) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:42:20.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:42:20.878+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:42:20.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:42:23.268+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:42:23.289+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:42:23.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:42:23.311+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:42:23.311+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:42:23.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.458 seconds
[2025-01-14T02:42:53.590+0000] {processor.py:186} INFO - Started process (PID=55948) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:42:53.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:42:53.594+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:42:53.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:42:56.086+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:42:56.103+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:42:56.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:42:56.127+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:42:56.126+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:42:56.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.560 seconds
[2025-01-14T02:43:26.255+0000] {processor.py:186} INFO - Started process (PID=56023) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:43:26.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:43:26.260+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:43:26.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:43:28.786+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:43:28.803+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:43:28.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:43:28.823+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:43:28.822+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:43:28.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.589 seconds
[2025-01-14T02:43:59.263+0000] {processor.py:186} INFO - Started process (PID=56101) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:43:59.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:43:59.267+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:43:59.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:44:01.639+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:44:01.657+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:44:01.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:44:01.677+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:44:01.677+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:44:01.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.437 seconds
[2025-01-14T02:44:32.222+0000] {processor.py:186} INFO - Started process (PID=56166) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:44:32.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:44:32.226+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:44:32.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:44:34.782+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:44:34.800+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:44:34.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:44:34.830+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:44:34.830+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:44:34.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.637 seconds
[2025-01-14T02:45:04.947+0000] {processor.py:186} INFO - Started process (PID=56232) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:45:04.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:45:04.951+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:45:04.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:45:07.317+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:45:07.335+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:45:07.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:45:07.354+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:45:07.353+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:45:07.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.427 seconds
[2025-01-14T02:45:38.162+0000] {processor.py:186} INFO - Started process (PID=56297) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:45:38.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:45:38.165+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:45:38.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:45:40.571+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:45:40.588+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:45:40.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:45:40.612+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:45:40.612+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:45:40.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.476 seconds
[2025-01-14T02:46:10.812+0000] {processor.py:186} INFO - Started process (PID=56363) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:46:10.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:46:10.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:46:10.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:46:13.275+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:46:13.291+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:46:13.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:46:13.311+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:46:13.311+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:46:13.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.520 seconds
[2025-01-14T02:46:43.722+0000] {processor.py:186} INFO - Started process (PID=56438) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:46:43.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:46:43.726+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:46:43.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:46:46.160+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:46:46.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:46:46.177+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:46:46.196+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:46:46.196+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:46:46.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.495 seconds
[2025-01-14T02:47:17.023+0000] {processor.py:186} INFO - Started process (PID=56505) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:47:17.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:47:17.027+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:47:17.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:47:19.490+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:47:19.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:47:19.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:47:19.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:47:19.527+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:47:19.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.528 seconds
[2025-01-14T02:47:49.973+0000] {processor.py:186} INFO - Started process (PID=56571) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:47:49.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:47:49.977+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:47:49.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:47:52.383+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:47:52.398+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:47:52.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:47:52.420+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:47:52.420+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:47:52.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.470 seconds
[2025-01-14T02:48:22.954+0000] {processor.py:186} INFO - Started process (PID=56643) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:48:22.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:48:22.959+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:48:22.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:48:25.311+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:48:25.325+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:48:25.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:48:25.347+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:48:25.347+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:48:25.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.414 seconds
[2025-01-14T02:48:56.162+0000] {processor.py:186} INFO - Started process (PID=56707) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:48:56.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:48:56.166+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:48:56.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:48:58.553+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:48:58.572+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:48:58.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:48:58.593+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:48:58.593+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:48:58.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.455 seconds
[2025-01-14T02:49:28.766+0000] {processor.py:186} INFO - Started process (PID=56774) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:49:28.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:49:28.770+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:49:28.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:49:31.226+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:49:31.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:49:31.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:49:31.261+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:49:31.261+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:49:31.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.519 seconds
[2025-01-14T02:50:01.972+0000] {processor.py:186} INFO - Started process (PID=56846) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:50:01.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:50:01.976+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:50:01.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:50:04.373+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:50:04.388+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:50:04.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:50:04.407+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:50:04.407+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:50:04.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.460 seconds
[2025-01-14T02:50:34.948+0000] {processor.py:186} INFO - Started process (PID=56915) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:50:34.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:50:34.952+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:50:34.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:50:37.333+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:50:37.349+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:50:37.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:50:37.369+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:50:37.369+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:50:37.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.446 seconds
[2025-01-14T02:51:07.503+0000] {processor.py:186} INFO - Started process (PID=56982) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:51:07.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:51:07.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:07.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:51:09.969+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:51:09.991+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:09.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:51:10.009+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:10.009+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:51:10.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.530 seconds
[2025-01-14T02:51:40.283+0000] {processor.py:186} INFO - Started process (PID=57059) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:51:40.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:51:40.287+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:40.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:51:42.658+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:51:42.673+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:42.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:51:42.692+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:51:42.692+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:51:42.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T02:52:12.840+0000] {processor.py:186} INFO - Started process (PID=57124) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:52:12.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:52:12.845+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:52:12.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:52:15.301+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:52:15.317+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:52:15.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:52:15.337+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:52:15.337+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:52:15.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.519 seconds
[2025-01-14T02:52:45.434+0000] {processor.py:186} INFO - Started process (PID=57191) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:52:45.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:52:45.439+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:52:45.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:52:47.826+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:52:47.842+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:52:47.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:52:47.862+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:52:47.862+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:52:47.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.449 seconds
[2025-01-14T02:53:18.685+0000] {processor.py:186} INFO - Started process (PID=57258) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:53:18.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:53:18.689+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:53:18.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:53:21.130+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:53:21.147+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:53:21.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:53:21.167+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:53:21.166+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:53:21.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.503 seconds
[2025-01-14T02:53:51.883+0000] {processor.py:186} INFO - Started process (PID=57338) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:53:51.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:53:51.887+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:53:51.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:53:54.288+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:53:54.307+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:53:54.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:53:54.327+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:53:54.326+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:53:54.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.469 seconds
[2025-01-14T02:54:25.007+0000] {processor.py:186} INFO - Started process (PID=57406) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:54:25.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:54:25.012+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:54:25.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:54:27.573+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:54:27.589+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:54:27.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:54:27.608+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:54:27.608+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:54:27.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.624 seconds
[2025-01-14T02:54:57.927+0000] {processor.py:186} INFO - Started process (PID=57474) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:54:57.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:54:57.931+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:54:57.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:55:00.449+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:55:00.465+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:55:00.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:55:00.485+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:55:00.485+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:55:00.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.580 seconds
[2025-01-14T02:55:31.293+0000] {processor.py:186} INFO - Started process (PID=57538) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:55:31.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:55:31.297+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:55:31.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:55:33.931+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:55:33.947+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:55:33.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:55:33.967+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:55:33.967+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:55:33.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.697 seconds
[2025-01-14T02:56:04.623+0000] {processor.py:186} INFO - Started process (PID=57605) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:56:04.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:56:04.627+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:56:04.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:56:07.227+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:56:07.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:56:07.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:56:07.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:56:07.262+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:56:07.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.662 seconds
[2025-01-14T02:56:37.536+0000] {processor.py:186} INFO - Started process (PID=57677) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:56:37.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:56:37.540+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:56:37.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:56:40.093+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:56:40.109+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:56:40.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:56:40.128+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:56:40.128+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:56:40.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.613 seconds
[2025-01-14T02:57:10.508+0000] {processor.py:186} INFO - Started process (PID=57746) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:57:10.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:57:10.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:57:10.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:57:13.031+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:57:13.047+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:57:13.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:57:13.069+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:57:13.068+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:57:13.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.582 seconds
[2025-01-14T02:57:43.411+0000] {processor.py:186} INFO - Started process (PID=57810) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:57:43.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:57:43.415+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:57:43.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:57:46.000+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:57:46.016+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:57:46.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:57:46.039+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:57:46.039+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:57:46.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.650 seconds
[2025-01-14T02:58:16.458+0000] {processor.py:186} INFO - Started process (PID=57888) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:58:16.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:58:16.462+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:58:16.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:58:18.979+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:58:18.994+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:58:18.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:58:19.015+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:58:19.015+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:58:19.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.579 seconds
[2025-01-14T02:58:49.710+0000] {processor.py:186} INFO - Started process (PID=57952) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:58:49.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:58:49.714+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:58:49.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:58:52.117+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:58:52.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:58:52.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:58:52.152+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:58:52.152+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:58:52.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.463 seconds
[2025-01-14T02:59:22.447+0000] {processor.py:186} INFO - Started process (PID=58024) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:59:22.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:59:22.451+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:59:22.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:59:24.994+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:59:25.009+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:59:25.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:59:25.031+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:59:25.031+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:59:25.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.603 seconds
[2025-01-14T02:59:55.209+0000] {processor.py:186} INFO - Started process (PID=58092) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:59:55.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T02:59:55.214+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:59:55.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:59:57.712+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T02:59:57.728+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:59:57.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T02:59:57.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T02:59:57.750+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T02:59:57.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.564 seconds
[2025-01-14T03:00:28.310+0000] {processor.py:186} INFO - Started process (PID=58155) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:00:28.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:00:28.314+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:00:28.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:00:30.856+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:00:30.878+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:00:30.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:00:30.900+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:00:30.899+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:00:30.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.613 seconds
[2025-01-14T03:01:01.572+0000] {processor.py:186} INFO - Started process (PID=58222) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:01:01.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:01:01.576+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:01:01.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:01:04.121+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:01:04.137+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:01:04.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:01:04.159+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:01:04.159+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:01:04.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.611 seconds
[2025-01-14T03:01:34.290+0000] {processor.py:186} INFO - Started process (PID=58294) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:01:34.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:01:34.294+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:01:34.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:01:36.846+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:01:36.862+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:01:36.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:01:36.882+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:01:36.882+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:01:36.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.614 seconds
[2025-01-14T03:02:07.184+0000] {processor.py:186} INFO - Started process (PID=58362) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:02:07.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:02:07.189+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:02:07.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:02:09.591+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:02:09.607+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:02:09.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:02:09.626+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:02:09.626+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:02:09.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.463 seconds
[2025-01-14T03:02:40.212+0000] {processor.py:186} INFO - Started process (PID=58426) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:02:40.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:02:40.217+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:02:40.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:02:42.663+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:02:42.682+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:02:42.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:02:42.705+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:02:42.705+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:02:42.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.517 seconds
[2025-01-14T03:03:13.606+0000] {processor.py:186} INFO - Started process (PID=58494) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:03:13.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:03:13.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:03:13.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:03:16.092+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:03:16.109+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:03:16.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:03:16.127+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:03:16.127+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:03:16.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.545 seconds
[2025-01-14T03:03:46.959+0000] {processor.py:186} INFO - Started process (PID=58569) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:03:46.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:03:46.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:03:46.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:03:49.475+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:03:49.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:03:49.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:03:49.514+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:03:49.513+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:03:49.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.579 seconds
[2025-01-14T03:04:19.619+0000] {processor.py:186} INFO - Started process (PID=58639) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:04:19.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:04:19.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:04:19.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:04:22.112+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:04:22.128+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:04:22.127+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:04:22.147+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:04:22.147+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:04:22.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.549 seconds
[2025-01-14T03:04:52.569+0000] {processor.py:186} INFO - Started process (PID=58721) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:04:52.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:04:52.574+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:04:52.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:04:54.947+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:04:54.963+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:04:54.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:04:54.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:04:54.981+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:04:54.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T03:05:25.390+0000] {processor.py:186} INFO - Started process (PID=58785) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:05:25.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:05:25.394+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:05:25.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:05:27.867+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:05:27.883+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:05:27.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:05:27.903+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:05:27.903+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:05:27.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.534 seconds
[2025-01-14T03:05:57.985+0000] {processor.py:186} INFO - Started process (PID=58853) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:05:57.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:05:57.989+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:05:57.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:06:00.418+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:06:00.434+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:06:00.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:06:00.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:06:00.456+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:06:00.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.493 seconds
[2025-01-14T03:06:31.385+0000] {processor.py:186} INFO - Started process (PID=58921) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:06:31.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:06:31.390+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:06:31.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:06:33.771+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:06:33.786+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:06:33.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:06:33.806+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:06:33.805+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:06:33.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.442 seconds
[2025-01-14T03:07:03.892+0000] {processor.py:186} INFO - Started process (PID=58985) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:07:03.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:07:03.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:07:03.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:07:06.266+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:07:06.283+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:07:06.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:07:06.303+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:07:06.303+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:07:06.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.433 seconds
[2025-01-14T03:07:36.518+0000] {processor.py:186} INFO - Started process (PID=59049) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:07:36.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:07:36.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:07:36.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:07:38.933+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:07:38.949+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:07:38.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:07:38.968+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:07:38.968+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:07:38.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.473 seconds
[2025-01-14T03:08:09.194+0000] {processor.py:186} INFO - Started process (PID=59114) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:08:09.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:08:09.199+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:08:09.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:08:11.604+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:08:11.622+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:08:11.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:08:11.643+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:08:11.642+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:08:11.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.470 seconds
[2025-01-14T03:08:42.619+0000] {processor.py:186} INFO - Started process (PID=59179) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:08:42.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:08:42.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:08:42.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:08:45.041+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:08:45.058+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:08:45.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:08:45.079+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:08:45.078+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:08:45.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.481 seconds
[2025-01-14T03:09:15.298+0000] {processor.py:186} INFO - Started process (PID=59243) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:09:15.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:09:15.302+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:09:15.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:09:17.849+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:09:17.868+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:09:17.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:09:17.889+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:09:17.889+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:09:17.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.617 seconds
[2025-01-14T03:09:48.006+0000] {processor.py:186} INFO - Started process (PID=59312) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:09:48.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:09:48.010+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:09:48.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:09:50.559+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:09:50.576+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:09:50.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:09:50.596+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:09:50.596+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:09:50.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.613 seconds
[2025-01-14T03:10:21.354+0000] {processor.py:186} INFO - Started process (PID=59388) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:10:21.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:10:21.358+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:10:21.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:10:23.772+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:10:23.788+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:10:23.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:10:23.808+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:10:23.808+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:10:23.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.476 seconds
[2025-01-14T03:10:54.362+0000] {processor.py:186} INFO - Started process (PID=59458) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:10:54.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:10:54.366+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:10:54.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:10:56.854+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:10:56.869+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:10:56.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:10:56.891+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:10:56.891+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:10:56.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.551 seconds
[2025-01-14T03:11:27.815+0000] {processor.py:186} INFO - Started process (PID=59533) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:11:27.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:11:27.819+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:11:27.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:11:30.302+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:11:30.319+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:11:30.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:11:30.340+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:11:30.340+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:11:30.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.550 seconds
[2025-01-14T03:12:00.563+0000] {processor.py:186} INFO - Started process (PID=59602) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:12:00.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:12:00.568+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:12:00.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:12:03.041+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:12:03.061+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:12:03.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:12:03.085+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:12:03.085+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:12:03.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.552 seconds
[2025-01-14T03:12:33.385+0000] {processor.py:186} INFO - Started process (PID=59679) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:12:33.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:12:33.390+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:12:33.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:12:35.853+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:12:35.876+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:12:35.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:12:35.895+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:12:35.895+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:12:35.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.534 seconds
[2025-01-14T03:13:06.052+0000] {processor.py:186} INFO - Started process (PID=59748) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:13:06.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:13:06.056+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:13:06.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:13:08.479+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:13:08.494+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:13:08.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:13:08.515+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:13:08.515+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:13:08.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.483 seconds
[2025-01-14T03:13:38.604+0000] {processor.py:186} INFO - Started process (PID=59815) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:13:38.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:13:38.609+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:13:38.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:13:41.008+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:13:41.023+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:13:41.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:13:41.045+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:13:41.045+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:13:41.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.461 seconds
[2025-01-14T03:14:11.149+0000] {processor.py:186} INFO - Started process (PID=59879) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:14:11.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:14:11.153+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:14:11.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:14:13.526+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:14:13.541+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:14:13.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:14:13.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:14:13.563+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:14:13.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.434 seconds
[2025-01-14T03:14:43.921+0000] {processor.py:186} INFO - Started process (PID=59942) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:14:43.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:14:43.925+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:14:43.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:14:46.307+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:14:46.323+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:14:46.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:14:46.341+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:14:46.341+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:14:46.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.444 seconds
[2025-01-14T03:15:16.619+0000] {processor.py:186} INFO - Started process (PID=60007) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:15:16.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:15:16.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:15:16.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:15:19.011+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:15:19.025+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:15:19.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:15:19.046+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:15:19.045+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:15:19.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.448 seconds
[2025-01-14T03:15:49.204+0000] {processor.py:186} INFO - Started process (PID=60072) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:15:49.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:15:49.208+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:15:49.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:15:51.599+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:15:51.614+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:15:51.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:15:51.634+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:15:51.634+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:15:51.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.451 seconds
[2025-01-14T03:16:21.978+0000] {processor.py:186} INFO - Started process (PID=60136) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:16:21.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:16:21.982+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:16:21.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:16:24.409+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:16:24.425+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:16:24.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:16:24.445+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:16:24.445+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:16:24.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.489 seconds
[2025-01-14T03:16:54.544+0000] {processor.py:186} INFO - Started process (PID=60206) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:16:54.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:16:54.548+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:16:54.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:16:56.960+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:16:56.976+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:16:56.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:16:56.996+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:16:56.996+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:16:57.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.474 seconds
[2025-01-14T03:17:27.950+0000] {processor.py:186} INFO - Started process (PID=60270) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:17:27.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:17:27.954+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:17:27.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:17:30.433+0000] {processor.py:925} INFO - DAG(s) 'dag_init' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:17:30.449+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:17:30.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:17:30.469+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:17:30.468+0000] {dag.py:4180} INFO - Setting next_dagrun for dag_init to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:17:30.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.543 seconds
[2025-01-14T03:25:14.063+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:25:14.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:25:14.071+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:25:14.138+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:25:14.447+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.446+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:train_and_update_model
[2025-01-14T03:25:14.469+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.468+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:train_and_update_model
[2025-01-14T03:25:14.483+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.483+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:train_and_update_model
[2025-01-14T03:25:14.500+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.500+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:train_and_update_model
[2025-01-14T03:25:14.513+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.513+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:train_and_update_model
[2025-01-14T03:25:14.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.530+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:train_and_update_model
[2025-01-14T03:25:14.553+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.552+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:train_and_update_model
[2025-01-14T03:25:14.578+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.578+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:crawl_tomato_images
[2025-01-14T03:25:14.600+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.599+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:crawl_tomato_images
[2025-01-14T03:25:14.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.622+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:crawl_tomato_images
[2025-01-14T03:25:14.646+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.645+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:crawl_tomato_images
[2025-01-14T03:25:14.663+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.663+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:crawl_tomato_images
[2025-01-14T03:25:14.681+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.680+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:crawl_tomato_images
[2025-01-14T03:25:14.699+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.699+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:crawl_tomato_images
[2025-01-14T03:25:14.730+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.729+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:predict_tomato_images
[2025-01-14T03:25:14.752+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.751+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:predict_tomato_images
[2025-01-14T03:25:14.774+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.773+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:predict_tomato_images
[2025-01-14T03:25:14.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.795+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:predict_tomato_images
[2025-01-14T03:25:14.813+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.812+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:predict_tomato_images
[2025-01-14T03:25:14.835+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.835+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:predict_tomato_images
[2025-01-14T03:25:14.859+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.859+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:predict_tomato_images
[2025-01-14T03:25:14.861+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.860+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:25:14.898+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.897+0000] {dag.py:3262} INFO - Creating ORM DAG for predict_tomato_images
[2025-01-14T03:25:14.899+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.899+0000] {dag.py:3262} INFO - Creating ORM DAG for crawl_tomato_images
[2025-01-14T03:25:14.901+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.900+0000] {dag.py:3262} INFO - Creating ORM DAG for train_and_update_model
[2025-01-14T03:25:14.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.922+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:25:14.929+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.929+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:25:14.938+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:14.938+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:25:15.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.968 seconds
[2025-01-14T03:25:45.177+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:25:45.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:25:45.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:45.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:25:45.201+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:25:45.229+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:45.228+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:25:45.257+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:45.257+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:25:45.263+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:45.262+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:25:45.266+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:25:45.266+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:25:45.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.116 seconds
[2025-01-14T03:26:16.098+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:26:16.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:26:16.101+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:16.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:26:16.118+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:26:16.146+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:16.146+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:26:16.173+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:16.173+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:26:16.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:16.178+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:26:16.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:16.181+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:26:16.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.110 seconds
[2025-01-14T03:26:47.015+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:26:47.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:26:47.018+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:47.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:26:47.038+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:26:47.068+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:47.067+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:26:47.097+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:47.096+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:26:47.103+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:47.102+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:26:47.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:26:47.106+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:26:47.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.114 seconds
[2025-01-14T03:27:17.331+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:27:17.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:27:17.335+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:17.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:27:17.354+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:27:17.386+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:17.386+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:27:17.416+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:17.416+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:27:17.422+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:17.422+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:27:17.425+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:17.425+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:27:17.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.124 seconds
[2025-01-14T03:27:48.238+0000] {processor.py:186} INFO - Started process (PID=387) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:27:48.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:27:48.241+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:48.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:27:48.256+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:27:48.280+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:48.279+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:27:48.303+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:48.303+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:27:48.308+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:48.308+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:27:48.312+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:27:48.311+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:27:48.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.097 seconds
[2025-01-14T03:28:18.551+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:28:18.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:28:18.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:18.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:28:18.568+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:28:18.599+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:18.598+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:28:18.624+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:18.624+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:28:18.630+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:18.630+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:28:18.633+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:18.633+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:28:18.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.112 seconds
[2025-01-14T03:28:49.503+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:28:49.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:28:49.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:49.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:28:49.526+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:28:49.557+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:49.556+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:28:49.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:49.584+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:28:49.591+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:49.590+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:28:49.594+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:28:49.594+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:28:49.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.113 seconds
[2025-01-14T03:29:19.698+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:29:19.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:29:19.701+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:19.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:29:19.715+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:29:19.744+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:19.744+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:29:19.771+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:19.771+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:29:19.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:19.776+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:29:19.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:19.779+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:29:19.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.105 seconds
[2025-01-14T03:29:29.632+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:29:29.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:29:29.635+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:29.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:29:29.658+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:29:29.685+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:29.685+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:29:29.711+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:29.711+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:29:29.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:29.717+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:29:29.720+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:29:29.720+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:29:29.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.118 seconds
[2025-01-14T03:30:00.287+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:30:00.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:30:00.290+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:00.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:30:00.305+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:30:00.329+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:00.328+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:30:00.353+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:00.353+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:30:00.358+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:00.358+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:30:00.361+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:00.360+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:30:00.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.094 seconds
[2025-01-14T03:30:30.649+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:30:30.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:30:30.652+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:30.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:30:30.669+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:30:30.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:30.695+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:30:30.727+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:30.726+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:30:30.734+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:30.734+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:30:30.738+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:30:30.738+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:30:30.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.115 seconds
[2025-01-14T03:31:01.152+0000] {processor.py:186} INFO - Started process (PID=795) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:31:01.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:31:01.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:01.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:31:01.173+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:31:01.204+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:01.204+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:31:01.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:01.228+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:31:01.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:01.234+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:31:01.238+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:01.238+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:31:01.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.111 seconds
[2025-01-14T03:31:31.785+0000] {processor.py:186} INFO - Started process (PID=854) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:31:31.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:31:31.788+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:31.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:31:31.804+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:31:31.828+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:31.828+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:31:31.853+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:31.853+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:31:31.858+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:31.858+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:31:31.861+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:31:31.861+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:31:31.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.099 seconds
[2025-01-14T03:32:02.617+0000] {processor.py:186} INFO - Started process (PID=918) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:32:02.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:32:02.621+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:02.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:32:02.639+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:32:02.665+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:02.665+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:32:02.690+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:02.690+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:32:02.695+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:02.695+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:32:02.699+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:02.699+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:32:02.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.106 seconds
[2025-01-14T03:32:32.848+0000] {processor.py:186} INFO - Started process (PID=978) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:32:32.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:32:32.851+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:32.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:32:32.868+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:32:32.894+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:32.894+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:32:32.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:32.922+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:32:32.928+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:32.928+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:32:32.931+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:32:32.931+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:32:32.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.113 seconds
[2025-01-14T03:33:03.809+0000] {processor.py:186} INFO - Started process (PID=1047) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:33:03.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:33:03.812+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:03.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:33:03.830+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:33:03.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:03.864+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:33:03.889+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:03.889+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:33:03.895+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:03.895+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:33:03.898+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:03.898+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:33:03.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.113 seconds
[2025-01-14T03:33:34.239+0000] {processor.py:186} INFO - Started process (PID=1116) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:33:34.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:33:34.242+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:34.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:33:34.260+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:33:34.289+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:34.289+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:33:34.316+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:34.315+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:33:34.322+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:34.322+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:33:34.325+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:33:34.325+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:33:34.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.111 seconds
[2025-01-14T03:34:05.314+0000] {processor.py:186} INFO - Started process (PID=1181) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:05.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:34:05.316+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:05.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:05.332+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:05.361+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:05.361+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:34:05.387+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:05.387+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:34:05.394+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:05.394+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:05.398+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:05.397+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:05.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.107 seconds
[2025-01-14T03:34:35.462+0000] {processor.py:186} INFO - Started process (PID=1246) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:35.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:34:35.464+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:35.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:35.482+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:35.506+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:35.506+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:34:35.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:35.531+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:34:35.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:35.537+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:35.541+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:35.541+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:35.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T03:34:55.799+0000] {processor.py:186} INFO - Started process (PID=1302) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:55.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:34:55.802+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:55.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:55.823+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:55.845+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:55.845+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:34:55.869+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:55.869+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:34:55.875+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:55.875+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:55.878+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:55.878+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:55.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.105 seconds
[2025-01-14T03:34:56.840+0000] {processor.py:186} INFO - Started process (PID=1303) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:56.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:34:56.843+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:56.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:56.878+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:56.911+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:56.911+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:34:56.940+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:56.939+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:34:56.945+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:56.945+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:56.948+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:56.948+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:56.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.138 seconds
[2025-01-14T03:34:57.113+0000] {processor.py:186} INFO - Started process (PID=1306) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:57.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:34:57.115+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:57.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:57.132+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:34:57.157+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:57.157+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:34:57.183+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:57.183+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:34:57.189+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:57.189+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:57.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:34:57.192+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:34:57.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T03:35:27.474+0000] {processor.py:186} INFO - Started process (PID=1369) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:35:27.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:35:27.478+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:27.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:35:27.500+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:35:27.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:27.530+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:35:27.560+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:27.560+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:35:27.568+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:27.567+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:35:27.571+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:27.571+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:35:27.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.121 seconds
[2025-01-14T03:35:58.409+0000] {processor.py:186} INFO - Started process (PID=1434) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:35:58.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:35:58.411+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:58.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:35:58.429+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:35:58.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:58.455+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:35:58.481+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:58.481+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:35:58.488+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:58.488+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:35:58.492+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:35:58.492+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:35:58.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.110 seconds
[2025-01-14T03:36:29.114+0000] {processor.py:186} INFO - Started process (PID=1499) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:36:29.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:36:29.117+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:29.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:36:29.136+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:36:29.162+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:29.162+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:36:29.187+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:29.187+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:36:29.194+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:29.194+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:36:29.197+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:29.196+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:36:29.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.109 seconds
[2025-01-14T03:36:59.501+0000] {processor.py:186} INFO - Started process (PID=1564) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:36:59.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:36:59.504+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:59.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:36:59.525+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:36:59.550+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:59.550+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:36:59.576+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:59.576+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:36:59.582+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:59.582+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:36:59.585+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:36:59.585+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:36:59.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.107 seconds
[2025-01-14T03:37:30.345+0000] {processor.py:186} INFO - Started process (PID=1629) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:37:30.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:37:30.348+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:37:30.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:37:30.369+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:37:30.402+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:37:30.402+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:37:30.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:37:30.432+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:37:30.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:37:30.440+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:37:30.444+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:37:30.444+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:37:30.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.126 seconds
[2025-01-14T03:38:00.776+0000] {processor.py:186} INFO - Started process (PID=1694) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:38:00.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:38:00.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:00.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:38:00.794+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:38:00.819+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:00.819+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:38:00.842+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:00.842+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:38:00.849+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:00.848+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:38:00.852+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:00.852+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:38:00.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.101 seconds
[2025-01-14T03:38:31.563+0000] {processor.py:186} INFO - Started process (PID=1759) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:38:31.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:38:31.566+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:31.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:38:31.584+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:38:31.611+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:31.610+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:38:31.636+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:31.636+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:38:31.642+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:31.642+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:38:31.646+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:38:31.646+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:38:31.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T03:39:02.193+0000] {processor.py:186} INFO - Started process (PID=1824) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:39:02.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:39:02.195+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:02.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:39:02.211+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:39:02.235+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:02.235+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:39:02.262+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:02.261+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:39:02.268+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:02.268+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:39:02.272+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:02.272+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:39:02.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T03:39:32.735+0000] {processor.py:186} INFO - Started process (PID=1889) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:39:32.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:39:32.737+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:32.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:39:32.754+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:39:32.779+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:32.779+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:39:32.802+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:32.802+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:39:32.808+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:32.808+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:39:32.812+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:39:32.811+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:39:32.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T03:40:03.008+0000] {processor.py:186} INFO - Started process (PID=1954) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:40:03.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:40:03.012+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:03.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:40:03.035+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:40:03.064+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:03.064+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:40:03.101+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:03.101+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:40:03.110+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:03.110+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:40:03.116+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:03.116+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:40:03.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.140 seconds
[2025-01-14T03:40:33.429+0000] {processor.py:186} INFO - Started process (PID=2019) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:40:33.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:40:33.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:33.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:40:33.449+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:40:33.477+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:33.477+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:40:33.505+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:33.505+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:40:33.513+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:33.512+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:40:33.516+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:40:33.516+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:40:33.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.113 seconds
[2025-01-14T03:41:29.920+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:41:29.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:41:29.924+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:41:29.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:41:29.969+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:41:30.028+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:41:30.028+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:41:30.061+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:41:30.061+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:41:30.068+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:41:30.068+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:41:30.072+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:41:30.072+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:41:30.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.186 seconds
[2025-01-14T03:42:01.039+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:42:01.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:42:01.043+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:01.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:42:01.069+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:42:01.097+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:01.097+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:42:01.130+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:01.130+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:42:01.136+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:01.136+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:42:01.139+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:01.139+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:42:01.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.130 seconds
[2025-01-14T03:42:31.248+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:42:31.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:42:31.253+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:31.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:42:31.274+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:42:31.310+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:31.310+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:42:31.337+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:31.337+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:42:31.344+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:31.344+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:42:31.347+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:42:31.347+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:42:31.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.124 seconds
[2025-01-14T03:43:01.551+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:01.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:43:01.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:01.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:01.577+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:01.607+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:01.607+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:43:01.638+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:01.637+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:43:01.647+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:01.646+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:43:01.650+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:01.650+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:43:01.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.124 seconds
[2025-01-14T03:43:05.265+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:05.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:43:05.269+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:05.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:05.290+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:05.319+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:05.318+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:43:05.343+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:05.343+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:43:05.349+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:05.349+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:43:05.352+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:05.352+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:43:05.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.112 seconds
[2025-01-14T03:43:35.454+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:35.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:43:35.458+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:35.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:35.473+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:43:35.501+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:35.501+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:43:35.528+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:35.528+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:43:35.535+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:35.534+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:43:35.538+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:43:35.538+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:43:35.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.107 seconds
[2025-01-14T03:44:06.217+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:44:06.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:44:06.221+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:06.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:44:06.237+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:44:06.268+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:06.268+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:44:06.294+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:06.294+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:44:06.300+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:06.300+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:44:06.304+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:06.303+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:44:06.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.111 seconds
[2025-01-14T03:44:36.528+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:44:36.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:44:36.532+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:36.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:44:36.547+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:44:36.575+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:36.575+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:44:36.602+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:36.601+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:44:36.607+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:36.607+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:44:36.610+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:44:36.610+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:44:36.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.107 seconds
[2025-01-14T03:45:07.137+0000] {processor.py:186} INFO - Started process (PID=539) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:45:07.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:45:07.141+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:07.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:45:07.156+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:45:07.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:07.180+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:45:07.205+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:07.205+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:45:07.211+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:07.211+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:45:07.214+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:07.214+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:45:07.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.102 seconds
[2025-01-14T03:45:37.270+0000] {processor.py:186} INFO - Started process (PID=604) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:45:37.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:45:37.275+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:37.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:45:37.289+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:45:37.312+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:37.311+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:45:37.336+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:37.336+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:45:37.342+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:37.342+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:45:37.345+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:45:37.345+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:45:37.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.095 seconds
[2025-01-14T03:46:08.226+0000] {processor.py:186} INFO - Started process (PID=668) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:46:08.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:46:08.230+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:08.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:46:08.244+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:46:08.267+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:08.267+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:46:08.290+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:08.290+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:46:08.296+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:08.295+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:46:08.299+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:08.298+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:46:08.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.094 seconds
[2025-01-14T03:46:38.589+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:46:38.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:46:38.593+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:38.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:46:38.608+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:46:38.633+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:38.633+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:46:38.656+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:38.656+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:46:38.662+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:38.662+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:46:38.665+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:46:38.665+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:46:38.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.096 seconds
[2025-01-14T03:47:09.360+0000] {processor.py:186} INFO - Started process (PID=798) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:47:09.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:47:09.364+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:09.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:47:09.378+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:47:09.403+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:09.402+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:47:09.426+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:09.426+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:47:09.432+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:09.431+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:47:09.435+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:09.435+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:47:09.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.096 seconds
[2025-01-14T03:47:40.058+0000] {processor.py:186} INFO - Started process (PID=863) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:47:40.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:47:40.062+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:40.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:47:40.075+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:47:40.101+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:40.101+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:47:40.123+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:40.123+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:47:40.128+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:40.128+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:47:40.133+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:47:40.133+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:47:40.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.101 seconds
[2025-01-14T03:48:10.868+0000] {processor.py:186} INFO - Started process (PID=928) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:10.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:48:10.873+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:10.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:10.887+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:10.912+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:10.911+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:48:10.934+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:10.934+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:48:10.940+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:10.940+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:48:10.944+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:10.943+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:48:10.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.099 seconds
[2025-01-14T03:48:25.181+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:25.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:48:25.186+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:25.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:25.205+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:25.203+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 156, in <module>
    crawl_task >> predict_task >> train_update_task
    ~~~~~~~~~~~^^~~~~~~~~~~~~~
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 104, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 263, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 229, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: predict_tomato_images>, <DAG: crawl_tomato_images>}
[2025-01-14T03:48:25.206+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:25.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.053 seconds
[2025-01-14T03:48:55.295+0000] {processor.py:186} INFO - Started process (PID=1042) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:55.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:48:55.299+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:55.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:55.312+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:48:55.311+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 156, in <module>
    crawl_task >> predict_task >> train_update_task
    ~~~~~~~~~~~^^~~~~~~~~~~~~~
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 104, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 263, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 229, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: predict_tomato_images>, <DAG: crawl_tomato_images>}
[2025-01-14T03:48:55.313+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:48:55.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.041 seconds
[2025-01-14T03:49:26.126+0000] {processor.py:186} INFO - Started process (PID=1107) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:49:26.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:49:26.129+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:26.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:49:26.144+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:26.142+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 156, in <module>
    crawl_task >> predict_task >> train_update_task
    ~~~~~~~~~~~^^~~~~~~~~~~~~~
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 104, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 263, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 229, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: crawl_tomato_images>, <DAG: predict_tomato_images>}
[2025-01-14T03:49:26.145+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:49:26.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.043 seconds
[2025-01-14T03:49:39.810+0000] {processor.py:186} INFO - Started process (PID=1124) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:49:39.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:49:39.813+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:49:39.834+0000] {processor.py:925} INFO - DAG(s) 'crawl_predict_train_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:49:39.944+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.942+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:crawl_predict_train_tomato_images
[2025-01-14T03:49:39.958+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.957+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:crawl_predict_train_tomato_images
[2025-01-14T03:49:39.967+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.967+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:crawl_predict_train_tomato_images
[2025-01-14T03:49:39.977+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.976+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:crawl_predict_train_tomato_images
[2025-01-14T03:49:39.987+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.986+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:crawl_predict_train_tomato_images
[2025-01-14T03:49:39.997+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:39.996+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:crawl_predict_train_tomato_images
[2025-01-14T03:49:40.010+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:40.009+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:crawl_predict_train_tomato_images
[2025-01-14T03:49:40.010+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:40.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:49:40.027+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:40.027+0000] {dag.py:3262} INFO - Creating ORM DAG for crawl_predict_train_tomato_images
[2025-01-14T03:49:40.041+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:49:40.041+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_predict_train_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:49:40.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.259 seconds
[2025-01-14T03:50:10.507+0000] {processor.py:186} INFO - Started process (PID=1189) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:10.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:50:10.510+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:10.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:10.524+0000] {processor.py:925} INFO - DAG(s) 'crawl_predict_train_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:10.547+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:10.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-14T03:50:10.570+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:10.570+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_predict_train_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:50:10.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.087 seconds
[2025-01-14T03:50:37.674+0000] {processor.py:186} INFO - Started process (PID=1244) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:37.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:50:37.676+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:37.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:37.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:37.691+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 154, in <module>
    crawl_task >> predict_task >> train_update_task
    ~~~~~~~~~~~^^~~~~~~~~~~~~~
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 104, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 263, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 229, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: predict_tomato_images>, <DAG: crawl_tomato_images>}
[2025-01-14T03:50:37.693+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:37.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.042 seconds
[2025-01-14T03:50:38.694+0000] {processor.py:186} INFO - Started process (PID=1245) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:38.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:50:38.696+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:38.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:38.713+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:50:38.711+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 154, in <module>
    crawl_task >> predict_task >> train_update_task
    ~~~~~~~~~~~^^~~~~~~~~~~~~~
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 104, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 263, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskmixin.py", line 229, in _set_relatives
    raise AirflowException(f"Tried to set relationships between tasks in more than one DAG: {dags}")
airflow.exceptions.AirflowException: Tried to set relationships between tasks in more than one DAG: {<DAG: crawl_tomato_images>, <DAG: predict_tomato_images>}
[2025-01-14T03:50:38.713+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:50:38.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.047 seconds
[2025-01-14T03:51:05.681+0000] {processor.py:186} INFO - Started process (PID=1310) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:05.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:51:05.685+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:05.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:05.702+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:05.839+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:05.839+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:51:05.863+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:05.863+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:51:05.868+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:05.868+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:51:05.871+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:05.871+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:51:05.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.221 seconds
[2025-01-14T03:51:06.728+0000] {processor.py:186} INFO - Started process (PID=1311) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:06.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:51:06.731+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:06.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:06.757+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:06.776+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:06.776+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:51:06.809+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:06.809+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:51:06.816+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:06.816+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:51:06.819+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:06.819+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:51:06.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.120 seconds
[2025-01-14T03:51:37.725+0000] {processor.py:186} INFO - Started process (PID=1376) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:37.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:51:37.728+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:37.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:37.743+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:51:37.766+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:37.765+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:51:37.790+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:37.790+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:51:37.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:37.795+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:51:37.799+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:51:37.799+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:51:37.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.095 seconds
[2025-01-14T03:52:08.483+0000] {processor.py:186} INFO - Started process (PID=1441) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:52:08.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:52:08.485+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:08.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:52:08.505+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:52:08.530+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:08.530+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:52:08.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:08.555+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:52:08.563+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:08.562+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:52:08.567+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:08.567+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:52:08.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.107 seconds
[2025-01-14T03:52:39.180+0000] {processor.py:186} INFO - Started process (PID=1506) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:52:39.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:52:39.182+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:39.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:52:39.197+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:52:39.221+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:39.221+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:52:39.248+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:39.247+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:52:39.253+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:39.253+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:52:39.257+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:52:39.256+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:52:39.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.098 seconds
[2025-01-14T03:53:10.144+0000] {processor.py:186} INFO - Started process (PID=1571) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:53:10.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:53:10.147+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:10.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:53:10.161+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:53:10.182+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:10.182+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:53:10.207+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:10.207+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:53:10.212+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:10.212+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:53:10.215+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:10.215+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:53:10.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.092 seconds
[2025-01-14T03:53:40.808+0000] {processor.py:186} INFO - Started process (PID=1636) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:53:40.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:53:40.811+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:40.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:53:40.829+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:53:40.857+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:40.856+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:53:40.882+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:40.881+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:53:40.888+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:40.887+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:53:40.891+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:53:40.891+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:53:40.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.106 seconds
[2025-01-14T03:54:11.104+0000] {processor.py:186} INFO - Started process (PID=1701) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:11.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:54:11.106+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:11.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:11.123+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:11.151+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:11.151+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:54:11.176+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:11.175+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:54:11.181+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:11.181+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:11.184+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:11.184+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:11.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T03:54:26.897+0000] {processor.py:186} INFO - Started process (PID=1712) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:26.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:54:26.900+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:26.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:26.921+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:26.947+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:26.947+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:54:26.973+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:26.973+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:54:26.981+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:26.981+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:26.985+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:26.985+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:27.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.114 seconds
[2025-01-14T03:54:27.284+0000] {processor.py:186} INFO - Started process (PID=1719) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:27.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:54:27.287+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:27.307+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:27.336+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.336+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:54:27.364+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.364+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:54:27.369+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.369+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:27.373+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.372+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:27.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.119 seconds
[2025-01-14T03:54:27.549+0000] {processor.py:186} INFO - Started process (PID=1722) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:27.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:54:27.552+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:27.570+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:27.597+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.597+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:54:27.623+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.622+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:54:27.628+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.628+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:27.632+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:27.631+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:27.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T03:54:57.817+0000] {processor.py:186} INFO - Started process (PID=1785) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:57.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:54:57.820+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:57.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:57.836+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:54:57.867+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:57.867+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:54:57.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:57.908+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:54:57.922+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:57.921+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:57.928+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:54:57.928+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:54:57.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.162 seconds
[2025-01-14T03:55:28.161+0000] {processor.py:186} INFO - Started process (PID=1850) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:55:28.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:55:28.164+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:28.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:55:28.181+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:55:28.207+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:28.207+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:55:28.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:28.232+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:55:28.238+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:28.237+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:55:28.241+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:28.241+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:55:28.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.105 seconds
[2025-01-14T03:55:38.706+0000] {processor.py:186} INFO - Started process (PID=1899) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:55:38.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:55:38.710+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:38.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:55:38.735+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:55:38.727+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 102, in <module>
    start_date=days_ago(1),
               ^^^^^^^^
NameError: name 'days_ago' is not defined
[2025-01-14T03:55:38.740+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:55:38.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.092 seconds
[2025-01-14T03:56:00.129+0000] {processor.py:186} INFO - Started process (PID=1920) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:56:00.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:56:00.132+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:00.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:56:00.151+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:56:00.183+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:00.183+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:56:00.211+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:00.210+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:56:00.217+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:00.217+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:56:00.220+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:00.220+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:56:00.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.119 seconds
[2025-01-14T03:56:30.508+0000] {processor.py:186} INFO - Started process (PID=1985) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:56:30.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:56:30.512+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:30.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:56:30.528+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:56:30.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:30.554+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:56:30.582+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:30.582+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:56:30.588+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:30.588+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:56:30.592+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:56:30.592+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:56:30.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T03:57:01.479+0000] {processor.py:186} INFO - Started process (PID=2049) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:01.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:57:01.481+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:01.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:01.497+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:01.523+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:01.523+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:57:01.547+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:01.547+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:57:01.552+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:01.552+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:57:01.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:01.555+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:57:01.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.100 seconds
[2025-01-14T03:57:09.944+0000] {processor.py:186} INFO - Started process (PID=2094) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:09.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:57:09.947+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:09.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:09.964+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:10.073+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:10.073+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:57:10.300+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:10.299+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:57:10.306+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:10.305+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:57:10.309+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:10.309+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:57:10.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.390 seconds
[2025-01-14T03:57:41.227+0000] {processor.py:186} INFO - Started process (PID=2159) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:41.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:57:41.230+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:41.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:41.251+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:57:41.276+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:41.276+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:57:41.303+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:41.303+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:57:41.310+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:41.309+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:57:41.313+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:57:41.313+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:57:41.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.111 seconds
[2025-01-14T03:58:12.233+0000] {processor.py:186} INFO - Started process (PID=2224) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:58:12.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:58:12.236+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:58:12.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:58:12.252+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:58:12.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:58:12.377+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:58:12.584+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:58:12.584+0000] {dag.py:3262} INFO - Creating ORM DAG for train_and_update_model
[2025-01-14T03:58:12.596+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:58:12.596+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:58:12.602+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:58:12.602+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:58:12.606+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:58:12.606+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:58:12.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.404 seconds
[2025-01-14T03:59:01.460+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:59:01.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:59:01.464+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:01.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:59:01.483+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:59:01.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:01.527+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:59:01.560+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:01.560+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:59:01.569+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:01.569+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:59:01.573+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:01.573+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:59:01.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.144 seconds
[2025-01-14T03:59:32.219+0000] {processor.py:186} INFO - Started process (PID=125) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:59:32.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T03:59:32.223+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:32.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:59:32.244+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T03:59:32.272+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:32.272+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T03:59:32.299+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:32.298+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T03:59:32.304+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:32.304+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T03:59:32.307+0000] {logging_mixin.py:190} INFO - [2025-01-14T03:59:32.307+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 02:00:00+00:00, run_after=2025-01-14 03:00:00+00:00
[2025-01-14T03:59:32.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.113 seconds
[2025-01-14T04:00:02.487+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:00:02.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:00:02.491+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:02.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:00:02.509+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:00:02.536+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:02.536+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:00:02.562+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:02.561+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:00:02.568+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:02.568+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:00:02.571+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:02.571+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T04:00:02.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.111 seconds
[2025-01-14T04:00:33.462+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:00:33.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:00:33.466+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:33.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:00:33.482+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:00:33.515+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:33.515+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:00:33.543+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:33.542+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:00:33.549+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:33.549+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:00:33.555+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:00:33.555+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 03:00:00+00:00, run_after=2025-01-14 04:00:00+00:00
[2025-01-14T04:00:33.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.123 seconds
[2025-01-14T04:01:04.598+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:04.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:01:04.601+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:04.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:04.615+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:04.644+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:04.644+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:01:04.671+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:04.671+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:01:04.677+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:04.677+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:01:04.681+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:04.680+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:01:04.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.107 seconds
[2025-01-14T04:01:35.075+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:35.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:01:35.078+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:35.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:35.094+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:35.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:35.125+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:01:35.150+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:35.150+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:01:35.156+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:35.155+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:01:35.159+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:35.159+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:01:35.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.112 seconds
[2025-01-14T04:01:44.982+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:44.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:01:44.986+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:44.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:45.002+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:01:45.027+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:45.027+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:01:45.050+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:45.050+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:01:45.055+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:45.055+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:01:45.058+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:01:45.058+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:01:45.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.102 seconds
[2025-01-14T04:02:15.648+0000] {processor.py:186} INFO - Started process (PID=508) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:02:15.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:02:15.651+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:15.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:02:15.666+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:02:15.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:15.688+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:02:15.718+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:15.717+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:02:15.724+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:15.723+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:02:15.727+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:15.727+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:02:15.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T04:02:46.431+0000] {processor.py:186} INFO - Started process (PID=566) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:02:46.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:02:46.435+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:46.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:02:46.453+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:02:46.484+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:46.483+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:02:46.515+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:46.514+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:02:46.522+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:46.522+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:02:46.525+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:02:46.525+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:02:46.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.121 seconds
[2025-01-14T04:03:17.306+0000] {processor.py:186} INFO - Started process (PID=622) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:03:17.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:03:17.310+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:17.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:03:17.324+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:03:17.346+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:17.346+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:03:17.371+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:17.370+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:03:17.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:17.377+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:03:17.381+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:17.380+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:03:17.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.102 seconds
[2025-01-14T04:03:47.771+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:03:47.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:03:47.775+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:47.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:03:47.794+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:03:47.822+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:47.822+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:03:47.852+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:47.852+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:03:47.858+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:47.857+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:03:47.861+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:03:47.861+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:03:47.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.118 seconds
[2025-01-14T04:04:14.874+0000] {processor.py:186} INFO - Started process (PID=719) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:04:14.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:04:14.877+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:14.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:04:14.897+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:04:15.013+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:15.013+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:04:15.037+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:15.037+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:04:15.042+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:15.042+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:04:15.045+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:15.045+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:04:15.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.197 seconds
[2025-01-14T04:04:45.876+0000] {processor.py:186} INFO - Started process (PID=784) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:04:45.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:04:45.880+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:45.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:04:45.897+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:04:45.924+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:45.924+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:04:45.948+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:45.947+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:04:45.953+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:45.953+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:04:45.957+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:04:45.957+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:04:45.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.105 seconds
[2025-01-14T04:05:16.939+0000] {processor.py:186} INFO - Started process (PID=849) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:05:16.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:05:16.943+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:16.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:05:16.959+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:05:16.987+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:16.987+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:05:17.010+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:17.010+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:05:17.016+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:17.016+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:05:17.020+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:17.020+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:05:17.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.109 seconds
[2025-01-14T04:05:47.849+0000] {processor.py:186} INFO - Started process (PID=914) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:05:47.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:05:47.853+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:47.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:05:47.868+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:05:47.893+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:47.893+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:05:47.917+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:47.917+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:05:47.923+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:47.922+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:05:47.926+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:05:47.926+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:05:47.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.100 seconds
[2025-01-14T04:06:18.112+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:06:18.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:06:18.117+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:18.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:06:18.134+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:06:18.161+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:18.160+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:06:18.187+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:18.187+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:06:18.193+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:18.192+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:06:18.196+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:18.196+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:06:18.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T04:06:48.273+0000] {processor.py:186} INFO - Started process (PID=1045) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:06:48.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:06:48.277+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:48.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:06:48.291+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:06:48.316+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:48.315+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:06:48.338+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:48.338+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:06:48.344+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:48.344+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:06:48.348+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:06:48.348+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:06:48.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.097 seconds
[2025-01-14T04:07:18.433+0000] {processor.py:186} INFO - Started process (PID=1110) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:07:18.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:07:18.437+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:18.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:07:18.451+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:07:18.477+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:18.477+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:07:18.501+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:18.500+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:07:18.506+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:18.506+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:07:18.509+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:18.509+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:07:18.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.098 seconds
[2025-01-14T04:07:29.685+0000] {processor.py:186} INFO - Started process (PID=1159) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:07:29.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:07:29.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:29.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:07:29.704+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:07:29.809+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:29.809+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:07:29.832+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:29.832+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:07:29.837+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:29.837+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:07:29.840+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:07:29.840+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:07:29.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.182 seconds
[2025-01-14T04:08:00.725+0000] {processor.py:186} INFO - Started process (PID=1224) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:08:00.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:08:00.729+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:00.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:08:00.743+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:08:00.769+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:00.769+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:08:00.795+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:00.794+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:08:00.801+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:00.800+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:08:00.804+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:00.804+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:08:00.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.102 seconds
[2025-01-14T04:08:31.072+0000] {processor.py:186} INFO - Started process (PID=1289) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:08:31.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:08:31.077+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:31.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:08:31.096+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:08:31.127+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:31.126+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:08:31.154+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:31.154+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:08:31.160+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:31.159+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:08:31.163+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:08:31.163+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:08:31.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.112 seconds
[2025-01-14T04:09:01.330+0000] {processor.py:186} INFO - Started process (PID=1354) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:09:01.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:09:01.334+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:01.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:09:01.351+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:09:01.379+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:01.379+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:09:01.405+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:01.405+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:09:01.413+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:01.413+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:09:01.417+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:01.417+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:09:01.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.113 seconds
[2025-01-14T04:09:32.151+0000] {processor.py:186} INFO - Started process (PID=1419) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:09:32.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:09:32.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:32.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:09:32.174+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:09:32.201+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:32.200+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:09:32.227+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:32.226+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:09:32.233+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:32.233+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:09:32.236+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:09:32.236+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:09:32.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T04:10:02.306+0000] {processor.py:186} INFO - Started process (PID=1484) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:10:02.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:10:02.311+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:02.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:10:02.329+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:10:02.352+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:02.352+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:10:02.379+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:02.379+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:10:02.384+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:02.384+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:10:02.387+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:02.387+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:10:02.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T04:10:33.776+0000] {processor.py:186} INFO - Started process (PID=1554) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:10:33.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:10:33.780+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:33.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:10:33.795+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:10:33.818+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:33.818+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:10:33.841+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:33.840+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:10:33.846+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:33.846+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:10:33.849+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:10:33.849+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:10:33.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.095 seconds
[2025-01-14T04:11:03.983+0000] {processor.py:186} INFO - Started process (PID=1609) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:11:03.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:11:03.988+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:03.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:11:04.014+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:11:04.052+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:04.052+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:11:04.084+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:04.084+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:11:04.092+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:04.091+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:11:04.095+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:04.095+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:11:04.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.144 seconds
[2025-01-14T04:11:34.825+0000] {processor.py:186} INFO - Started process (PID=1671) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:11:34.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:11:34.830+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:34.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:11:34.845+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:11:34.873+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:34.872+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:11:34.898+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:34.898+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:11:34.904+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:34.904+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:11:34.907+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:11:34.907+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:11:34.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T04:12:05.084+0000] {processor.py:186} INFO - Started process (PID=1729) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:12:05.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:12:05.088+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:05.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:12:05.104+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:12:05.130+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:05.129+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:12:05.154+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:05.154+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:12:05.160+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:05.160+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:12:05.163+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:05.163+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:12:05.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.100 seconds
[2025-01-14T04:12:35.428+0000] {processor.py:186} INFO - Started process (PID=1792) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:12:35.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:12:35.431+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:35.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:12:35.447+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:12:35.473+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:35.473+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:12:35.498+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:35.498+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:12:35.504+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:35.504+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:12:35.508+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:12:35.508+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:12:35.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.104 seconds
[2025-01-14T04:13:05.757+0000] {processor.py:186} INFO - Started process (PID=1851) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:13:05.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:13:05.761+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:05.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:13:05.779+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:13:05.809+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:05.809+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:13:05.835+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:05.835+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:13:05.841+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:05.841+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:13:05.845+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:05.845+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:13:05.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.116 seconds
[2025-01-14T04:13:36.027+0000] {processor.py:186} INFO - Started process (PID=1910) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:13:36.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:13:36.032+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:36.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:13:36.046+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:13:36.070+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:36.070+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:13:36.092+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:36.091+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:13:36.097+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:36.097+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:13:36.100+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:13:36.100+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:13:36.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.095 seconds
[2025-01-14T04:14:06.218+0000] {processor.py:186} INFO - Started process (PID=1964) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:14:06.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:14:06.222+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:06.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:14:06.238+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:14:06.268+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:06.267+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:14:06.292+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:06.292+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:14:06.299+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:06.299+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:14:06.303+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:06.302+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:14:06.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.109 seconds
[2025-01-14T04:14:36.643+0000] {processor.py:186} INFO - Started process (PID=2026) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:14:36.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:14:36.648+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:36.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:14:36.664+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:14:36.688+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:36.687+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:14:36.712+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:36.712+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:14:36.717+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:36.717+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:14:36.721+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:14:36.720+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:14:36.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.101 seconds
[2025-01-14T04:15:06.797+0000] {processor.py:186} INFO - Started process (PID=2091) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:15:06.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:15:06.801+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:06.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:15:06.814+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:15:06.837+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:06.836+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:15:06.860+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:06.860+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:15:06.865+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:06.865+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:15:06.868+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:06.868+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:15:06.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.093 seconds
[2025-01-14T04:15:36.992+0000] {processor.py:186} INFO - Started process (PID=2156) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:15:36.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:15:36.996+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:36.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:15:37.009+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'crawl_tomato_images', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:15:37.035+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:37.035+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:15:37.058+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:37.058+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:15:37.064+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:37.064+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:15:37.068+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:15:37.067+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:15:37.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.105 seconds
[2025-01-14T04:16:07.187+0000] {processor.py:186} INFO - Started process (PID=2221) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:16:07.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:16:07.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:07.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:16:07.208+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:16:07.236+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:07.235+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:16:07.266+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:07.265+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:16:07.274+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:07.274+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:16:07.278+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:07.278+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:16:07.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.116 seconds
[2025-01-14T04:16:38.109+0000] {processor.py:186} INFO - Started process (PID=2286) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:16:38.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:16:38.113+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:38.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:16:38.133+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:16:38.160+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:38.159+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:16:38.184+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:38.183+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:16:38.189+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:38.189+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:16:38.192+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:16:38.192+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:16:38.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.109 seconds
[2025-01-14T04:17:09.150+0000] {processor.py:186} INFO - Started process (PID=2351) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:09.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:17:09.154+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:09.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:09.171+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:09.195+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:09.194+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:17:09.219+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:09.219+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:17:09.225+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:09.224+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:17:09.228+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:09.228+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:17:09.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 0.108 seconds
[2025-01-14T04:17:13.050+0000] {processor.py:186} INFO - Started process (PID=2358) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:13.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:17:13.054+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:13.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:16.708+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:16.706+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:17:16.709+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:16.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.684 seconds
[2025-01-14T04:17:46.855+0000] {processor.py:186} INFO - Started process (PID=2438) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:46.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:17:46.859+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:46.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:48.722+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:17:48.721+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:17:48.723+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:17:48.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 1.893 seconds
[2025-01-14T04:18:19.120+0000] {processor.py:186} INFO - Started process (PID=2509) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:18:19.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:18:19.124+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:18:19.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:18:20.936+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:18:20.936+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:18:20.937+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:18:20.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 1.842 seconds
[2025-01-14T04:18:51.527+0000] {processor.py:186} INFO - Started process (PID=2581) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:18:51.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:18:51.531+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:18:51.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:18:53.620+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:18:53.620+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:18:53.621+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:18:53.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.120 seconds
[2025-01-14T04:19:24.208+0000] {processor.py:186} INFO - Started process (PID=2653) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:19:24.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:19:24.211+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:19:24.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:19:25.957+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:19:25.957+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:19:25.958+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:19:25.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 1.774 seconds
[2025-01-14T04:19:56.115+0000] {processor.py:186} INFO - Started process (PID=2727) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:19:56.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:19:56.118+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:19:56.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:19:58.114+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:19:58.114+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:19:58.115+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:19:58.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.029 seconds
[2025-01-14T04:20:28.497+0000] {processor.py:186} INFO - Started process (PID=2798) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:20:28.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:20:28.499+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:28.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:20:30.314+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:30.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from your_model import YourModel  # Giả sử bạn có một mô hình đã được định nghĩa ở đâu đó
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'your_model'
[2025-01-14T04:20:30.315+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:20:30.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 1.841 seconds
[2025-01-14T04:20:50.534+0000] {processor.py:186} INFO - Started process (PID=2806) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:20:50.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:20:50.537+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:50.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:20:53.343+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:53.343+0000] {font_manager.py:1639} INFO - generated new fontManager
[2025-01-14T04:20:53.759+0000] {logging_mixin.py:190} INFO - Creating new Ultralytics Settings v0.0.6 file ✅ 
View Ultralytics Settings with 'yolo settings' or at '/home/airflow/.config/Ultralytics/settings.json'
Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.
[2025-01-14T04:20:55.943+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:20:56.101+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:56.100+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:20:56.120+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:56.120+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:20:56.125+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:56.125+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:20:56.128+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:20:56.128+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:20:56.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 5.633 seconds
[2025-01-14T04:21:26.928+0000] {processor.py:186} INFO - Started process (PID=2888) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:21:26.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:21:26.931+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:21:26.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:21:30.477+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:21:30.502+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:21:30.502+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:21:30.527+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:21:30.527+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:21:30.533+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:21:30.533+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:21:30.536+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:21:30.536+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:21:30.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.631 seconds
[2025-01-14T04:22:00.735+0000] {processor.py:186} INFO - Started process (PID=2977) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:22:00.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:22:00.738+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:00.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:22:04.120+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:22:04.146+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:04.145+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:22:04.166+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:04.166+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:22:04.171+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:04.171+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:22:04.175+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:04.175+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:22:04.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.461 seconds
[2025-01-14T04:22:34.411+0000] {processor.py:186} INFO - Started process (PID=3062) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:22:34.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:22:34.414+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:34.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:22:37.702+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:22:37.725+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:37.724+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:22:37.745+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:37.744+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:22:37.750+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:37.750+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:22:37.753+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:22:37.753+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:22:37.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.363 seconds
[2025-01-14T04:23:08.182+0000] {processor.py:186} INFO - Started process (PID=3133) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:23:08.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:23:08.185+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:08.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:23:11.329+0000] {processor.py:925} INFO - DAG(s) 'train_and_update_model', 'predict_tomato_images', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:23:11.353+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:11.352+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:23:11.375+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:11.375+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:23:11.381+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:11.381+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:23:11.385+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:11.384+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:23:11.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.226 seconds
[2025-01-14T04:23:42.314+0000] {processor.py:186} INFO - Started process (PID=3198) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:23:42.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:23:42.317+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:42.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:23:45.407+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:23:45.427+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:45.427+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:23:45.449+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:45.449+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:23:45.454+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:45.454+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:23:45.457+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:23:45.457+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:23:45.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.181 seconds
[2025-01-14T04:24:15.722+0000] {processor.py:186} INFO - Started process (PID=3263) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:24:15.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:24:15.724+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:15.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:24:18.877+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:24:18.897+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:18.896+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:24:18.918+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:18.918+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:24:18.923+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:18.923+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:24:18.927+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:18.926+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:24:18.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.257 seconds
[2025-01-14T04:24:49.752+0000] {processor.py:186} INFO - Started process (PID=3328) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:24:49.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:24:49.756+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:49.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:24:52.867+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'train_and_update_model', 'crawl_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:24:52.888+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:52.887+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:24:52.908+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:52.908+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:24:52.913+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:52.913+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:24:52.917+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:24:52.917+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:24:52.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.186 seconds
[2025-01-14T04:25:23.427+0000] {processor.py:186} INFO - Started process (PID=3393) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:25:23.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:25:23.429+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:25:23.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:25:26.435+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:25:26.456+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:25:26.455+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:25:26.477+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:25:26.477+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:25:26.483+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:25:26.482+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:25:26.486+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:25:26.486+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:25:26.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.082 seconds
[2025-01-14T04:25:56.998+0000] {processor.py:186} INFO - Started process (PID=3458) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:25:57.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:25:57.002+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:25:57.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:26:00.324+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'predict_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:26:00.347+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:00.346+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:26:00.368+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:00.368+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:26:00.374+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:00.374+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:26:00.377+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:00.377+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:26:00.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.401 seconds
[2025-01-14T04:26:30.505+0000] {processor.py:186} INFO - Started process (PID=3536) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:26:30.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:26:30.507+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:30.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:26:33.765+0000] {processor.py:925} INFO - DAG(s) 'crawl_tomato_images', 'train_and_update_model', 'predict_tomato_images' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:26:33.789+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:33.788+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:26:33.810+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:33.809+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:26:33.815+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:33.815+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:26:33.818+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:26:33.818+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:26:33.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.339 seconds
[2025-01-14T04:27:04.072+0000] {processor.py:186} INFO - Started process (PID=3610) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:27:04.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:27:04.074+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:04.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:27:07.205+0000] {processor.py:925} INFO - DAG(s) 'predict_tomato_images', 'crawl_tomato_images', 'train_and_update_model' retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:27:07.226+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:07.226+0000] {dag.py:3239} INFO - Sync 3 DAGs
[2025-01-14T04:27:07.245+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:07.245+0000] {dag.py:4180} INFO - Setting next_dagrun for crawl_tomato_images to 2025-01-13 09:00:00+00:00, run_after=2025-01-14 09:00:00+00:00
[2025-01-14T04:27:07.250+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:07.250+0000] {dag.py:4180} INFO - Setting next_dagrun for predict_tomato_images to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:27:07.254+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:07.253+0000] {dag.py:4180} INFO - Setting next_dagrun for train_and_update_model to 2025-01-14 04:00:00+00:00, run_after=2025-01-14 05:00:00+00:00
[2025-01-14T04:27:07.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.202 seconds
[2025-01-14T04:27:37.810+0000] {processor.py:186} INFO - Started process (PID=3684) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:27:37.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:27:37.813+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:37.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:27:40.855+0000] {logging_mixin.py:190} INFO - Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...
[2025-01-14T04:27:42.199+0000] {logging_mixin.py:190} WARNING -   0%|          | 0.00/5.35M [00:00<?, ?B/s]
[2025-01-14T04:27:42.313+0000] {logging_mixin.py:190} WARNING -   2%|2         | 128k/5.35M [00:00<00:04, 1.15MB/s]
[2025-01-14T04:27:42.428+0000] {logging_mixin.py:190} WARNING -  12%|#1        | 640k/5.35M [00:00<00:01, 3.17MB/s]
[2025-01-14T04:27:42.543+0000] {logging_mixin.py:190} WARNING -  23%|##3       | 1.25M/5.35M [00:00<00:00, 4.33MB/s]
[2025-01-14T04:27:42.648+0000] {logging_mixin.py:190} WARNING -  33%|###2      | 1.75M/5.35M [00:00<00:00, 4.57MB/s]
[2025-01-14T04:27:42.759+0000] {logging_mixin.py:190} WARNING -  42%|####2     | 2.25M/5.35M [00:00<00:00, 4.63MB/s]
[2025-01-14T04:27:42.869+0000] {logging_mixin.py:190} WARNING -  56%|#####6    | 3.00M/5.35M [00:00<00:00, 5.48MB/s]
[2025-01-14T04:27:42.978+0000] {logging_mixin.py:190} WARNING -  70%|#######   | 3.75M/5.35M [00:00<00:00, 6.04MB/s]
[2025-01-14T04:27:43.083+0000] {logging_mixin.py:190} WARNING -  84%|########4 | 4.50M/5.35M [00:00<00:00, 6.49MB/s]
[2025-01-14T04:27:43.187+0000] {logging_mixin.py:190} WARNING -  98%|#########8| 5.25M/5.35M [00:00<00:00, 6.81MB/s]
[2025-01-14T04:27:43.201+0000] {logging_mixin.py:190} WARNING - 100%|##########| 5.35M/5.35M [00:01<00:00, 5.61MB/s]
[2025-01-14T04:27:43.663+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:27:45.155+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:27:45.214+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train
[2025-01-14T04:27:45.227+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:27:45.224+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:27:45.229+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:27:45.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 7.438 seconds
[2025-01-14T04:28:15.636+0000] {processor.py:186} INFO - Started process (PID=3830) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:28:15.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:28:15.638+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:28:15.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:28:18.702+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:28:18.720+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:28:18.774+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2
[2025-01-14T04:28:18.780+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:28:18.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:28:18.784+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:28:18.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.169 seconds
[2025-01-14T04:28:49.627+0000] {processor.py:186} INFO - Started process (PID=3932) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:28:49.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:28:49.629+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:28:49.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:28:52.504+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:28:52.524+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:28:52.577+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3
[2025-01-14T04:28:52.582+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:28:52.580+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:28:52.585+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:28:52.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.979 seconds
[2025-01-14T04:29:23.130+0000] {processor.py:186} INFO - Started process (PID=4034) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:29:23.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:29:23.133+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:29:23.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:29:26.149+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:29:26.168+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:29:26.227+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4
[2025-01-14T04:29:26.232+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:29:26.230+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:29:26.236+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:29:26.252+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.128 seconds
[2025-01-14T04:29:56.690+0000] {processor.py:186} INFO - Started process (PID=4136) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:29:56.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:29:56.693+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:29:56.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:29:59.610+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:29:59.627+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:29:59.679+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5
[2025-01-14T04:29:59.684+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:29:59.682+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:29:59.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:29:59.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.017 seconds
[2025-01-14T04:30:30.013+0000] {processor.py:186} INFO - Started process (PID=4238) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:30:30.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:30:30.015+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:30:30.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:30:33.128+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:30:33.146+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:30:33.203+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6
[2025-01-14T04:30:33.208+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:30:33.206+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:30:33.212+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:30:33.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.221 seconds
[2025-01-14T04:31:03.347+0000] {processor.py:186} INFO - Started process (PID=4343) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:31:03.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:31:03.350+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:31:03.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:31:06.448+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:31:06.469+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:31:06.521+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7
[2025-01-14T04:31:06.526+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:31:06.524+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:31:06.529+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:31:06.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.205 seconds
[2025-01-14T04:31:36.724+0000] {processor.py:186} INFO - Started process (PID=4458) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:31:36.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:31:36.726+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:31:36.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:31:40.134+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:31:40.156+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:31:40.207+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8
[2025-01-14T04:31:40.212+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:31:40.210+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:31:40.216+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:31:40.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.513 seconds
[2025-01-14T04:32:10.482+0000] {processor.py:186} INFO - Started process (PID=4574) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:10.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:32:10.485+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:32:10.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:13.559+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:32:13.576+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:32:13.628+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train9
[2025-01-14T04:32:13.633+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:32:13.631+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:32:13.640+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:13.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.180 seconds
[2025-01-14T04:32:44.153+0000] {processor.py:186} INFO - Started process (PID=4678) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:44.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:32:44.155+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:32:44.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:47.157+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:32:47.174+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:32:47.225+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10
[2025-01-14T04:32:47.230+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:32:47.228+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    import train
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:32:47.234+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:47.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.102 seconds
[2025-01-14T04:32:57.482+0000] {processor.py:186} INFO - Started process (PID=4748) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:32:57.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:32:57.484+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:32:57.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:33:00.676+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:33:00.696+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:33:00.748+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train11
[2025-01-14T04:33:00.753+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:33:00.751+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:33:00.756+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:33:00.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.295 seconds
[2025-01-14T04:33:31.592+0000] {processor.py:186} INFO - Started process (PID=4850) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:33:31.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:33:31.595+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:33:31.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:33:34.808+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:33:34.828+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:33:34.890+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train12
[2025-01-14T04:33:34.895+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:33:34.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:33:34.899+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:33:34.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.332 seconds
[2025-01-14T04:34:46.624+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:34:46.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:34:46.627+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:34:46.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:34:50.168+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:34:50.192+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:34:50.247+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train13
[2025-01-14T04:34:50.253+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:34:50.251+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:34:50.256+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:34:50.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.656 seconds
[2025-01-14T04:35:20.338+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:35:20.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:35:20.342+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:35:20.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:35:23.436+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:35:23.463+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:35:23.515+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train14
[2025-01-14T04:35:23.520+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:35:23.518+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:35:23.524+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:35:23.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.208 seconds
[2025-01-14T04:35:53.844+0000] {processor.py:186} INFO - Started process (PID=309) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:35:53.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:35:53.848+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:35:53.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:35:56.820+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:35:56.828+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:35:56.884+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train15
[2025-01-14T04:35:56.889+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:35:56.887+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:35:56.893+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:35:56.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.069 seconds
[2025-01-14T04:36:27.027+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:36:27.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:36:27.031+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:36:27.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:36:29.802+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:36:29.818+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:36:29.867+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train16, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train16
[2025-01-14T04:36:29.872+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:36:29.870+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:36:29.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:36:29.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.869 seconds
[2025-01-14T04:37:00.246+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:37:00.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:37:00.250+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:37:00.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:37:03.211+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:37:03.229+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:37:03.300+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train17, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train17
[2025-01-14T04:37:03.312+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:37:03.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:37:03.319+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:37:03.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.137 seconds
[2025-01-14T04:37:33.981+0000] {processor.py:186} INFO - Started process (PID=644) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:37:33.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:37:33.984+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:37:33.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:37:37.003+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:37:37.024+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:37:37.078+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train18
[2025-01-14T04:37:37.083+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:37:37.081+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:37:37.086+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:37:37.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.128 seconds
[2025-01-14T04:38:07.778+0000] {processor.py:186} INFO - Started process (PID=746) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:38:07.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:38:07.782+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:38:07.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:38:10.968+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:38:11.015+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:38:11.096+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train19, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train19
[2025-01-14T04:38:11.104+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:38:11.102+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:38:11.110+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:38:11.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.362 seconds
[2025-01-14T04:38:41.331+0000] {processor.py:186} INFO - Started process (PID=848) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:38:41.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:38:41.335+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:38:41.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:38:44.492+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:38:44.518+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:38:44.568+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train20, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train20
[2025-01-14T04:38:44.573+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:38:44.571+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:38:44.576+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:38:44.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.266 seconds
[2025-01-14T04:39:15.505+0000] {processor.py:186} INFO - Started process (PID=950) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:39:15.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:39:15.509+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:39:15.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:39:18.499+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:39:18.518+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:39:18.577+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train21, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train21
[2025-01-14T04:39:18.593+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:39:18.590+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:39:18.597+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:39:18.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.114 seconds
[2025-01-14T04:39:49.039+0000] {processor.py:186} INFO - Started process (PID=1052) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:39:49.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:39:49.044+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:39:49.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:39:52.790+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:39:52.806+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:39:52.857+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train22
[2025-01-14T04:39:52.861+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:39:52.860+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:39:52.866+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:39:52.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.854 seconds
[2025-01-14T04:40:23.176+0000] {processor.py:186} INFO - Started process (PID=1169) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:40:23.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:40:23.180+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:40:23.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:40:26.710+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:40:26.728+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:40:26.781+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train23, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train23
[2025-01-14T04:40:26.785+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:40:26.783+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:40:26.789+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:40:26.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.634 seconds
[2025-01-14T04:40:57.644+0000] {processor.py:186} INFO - Started process (PID=1275) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:40:57.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:40:57.649+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:40:57.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:41:00.680+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:41:00.699+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:41:00.755+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train24, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train24
[2025-01-14T04:41:00.765+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:41:00.762+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:41:00.770+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:41:00.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.152 seconds
[2025-01-14T04:41:31.396+0000] {processor.py:186} INFO - Started process (PID=1377) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:41:31.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:41:31.401+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:41:31.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:41:34.657+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:41:34.684+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:41:34.742+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train25, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train25
[2025-01-14T04:41:34.747+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:41:34.745+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:41:34.750+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:41:34.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.375 seconds
[2025-01-14T04:42:05.295+0000] {processor.py:186} INFO - Started process (PID=1491) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:42:05.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:42:05.299+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:42:05.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:42:08.341+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:42:08.375+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:42:08.435+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train26, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train26
[2025-01-14T04:42:08.440+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:42:08.438+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:42:08.444+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:42:08.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.172 seconds
[2025-01-14T04:42:39.148+0000] {processor.py:186} INFO - Started process (PID=1606) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:42:39.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:42:39.152+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:42:39.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:42:42.295+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:42:42.313+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:42:42.365+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train27, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train27
[2025-01-14T04:42:42.370+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:42:42.368+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:42:42.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:42:42.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.247 seconds
[2025-01-14T04:43:13.173+0000] {processor.py:186} INFO - Started process (PID=1728) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:43:13.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:43:13.178+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:43:13.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:43:16.296+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:43:16.313+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:43:16.369+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train28, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train28
[2025-01-14T04:43:16.374+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:43:16.372+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:43:16.378+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:43:16.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.226 seconds
[2025-01-14T04:43:47.287+0000] {processor.py:186} INFO - Started process (PID=1830) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:43:47.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:43:47.291+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:43:47.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:43:50.205+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:43:50.229+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:43:50.278+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train29, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train29
[2025-01-14T04:43:50.283+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:43:50.281+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:43:50.286+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:43:50.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.023 seconds
[2025-01-14T04:44:20.659+0000] {processor.py:186} INFO - Started process (PID=1932) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:44:20.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:44:20.664+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:44:20.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:44:23.725+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:44:23.742+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:44:23.792+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train30, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train30
[2025-01-14T04:44:23.796+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:44:23.795+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:44:23.800+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:44:23.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.160 seconds
[2025-01-14T04:44:53.883+0000] {processor.py:186} INFO - Started process (PID=2040) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:44:53.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:44:53.887+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:44:53.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:44:57.029+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:44:57.052+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:44:57.102+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train31, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train31
[2025-01-14T04:44:57.107+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:44:57.106+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=5, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:44:57.111+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:44:57.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.249 seconds
[2025-01-14T04:45:27.780+0000] {processor.py:186} INFO - Started process (PID=2151) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:45:27.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:45:27.785+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:45:27.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:45:30.634+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:45:30.662+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:45:30.728+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train32, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train32
[2025-01-14T04:45:30.733+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:45:30.732+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=1, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:45:30.737+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:45:30.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 2.977 seconds
[2025-01-14T04:46:01.285+0000] {processor.py:186} INFO - Started process (PID=2257) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:46:01.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:46:01.290+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:46:01.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:46:04.892+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:46:04.922+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:46:04.974+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train33, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train33
[2025-01-14T04:46:04.979+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:46:04.977+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=1, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:46:04.982+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:46:05.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.720 seconds
[2025-01-14T04:46:35.656+0000] {processor.py:186} INFO - Started process (PID=2359) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:46:35.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:46:35.660+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:46:35.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:46:39.124+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:46:39.140+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:46:39.196+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train34, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train34
[2025-01-14T04:46:39.202+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:46:39.199+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=1, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:46:39.206+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:46:39.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.574 seconds
[2025-01-14T04:47:09.611+0000] {processor.py:186} INFO - Started process (PID=2461) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:47:09.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:47:09.615+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:47:09.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:47:12.789+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:47:12.811+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:47:12.866+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train35, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train35
[2025-01-14T04:47:12.870+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:47:12.869+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=1, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:47:12.873+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:47:12.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.286 seconds
[2025-01-14T04:47:43.673+0000] {processor.py:186} INFO - Started process (PID=2563) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:47:43.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:47:43.678+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:47:43.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:47:46.693+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:47:46.718+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:47:46.771+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train36, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train36
[2025-01-14T04:47:46.775+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:47:46.774+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=1, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:47:46.780+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:47:46.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.130 seconds
[2025-01-14T04:48:16.875+0000] {processor.py:186} INFO - Started process (PID=2666) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:48:16.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:48:16.879+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:48:16.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:48:20.605+0000] {logging_mixin.py:190} INFO - New https://pypi.org/project/ultralytics/8.3.61 available 😃 Update with 'pip install -U ultralytics'
[2025-01-14T04:48:20.624+0000] {logging_mixin.py:190} INFO - Ultralytics 8.3.60 🚀 Python-3.12.7 torch-2.5.1+cu124 CPU (AMD Ryzen 7 4800H with Radeon Graphics)
[2025-01-14T04:48:20.679+0000] {logging_mixin.py:190} INFO - engine/trainer: task=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train37, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train37
[2025-01-14T04:48:20.683+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:48:20.682+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/craw_check_update.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 562, in get_dataset
    data = check_det_dataset(self.args.data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/data/utils.py", line 316, in check_det_dataset
    file = check_file(dataset)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/utils/checks.py", line 520, in check_file
    raise FileNotFoundError(f"'{file}' does not exist")
FileNotFoundError: 'data.yaml' does not exist

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/craw_check_update.py", line 12, in <module>
    from train import train_yolo
  File "/opt/airflow/dags/train.py", line 7, in <module>
    results = model.train(data="data.yaml", epochs=1, imgsz=240)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/model.py", line 800, in train
    self.trainer = (trainer or self._smart_load("trainer"))(overrides=args, _callbacks=self.callbacks)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 133, in __init__
    self.trainset, self.testset = self.get_dataset()
                                  ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/ultralytics/engine/trainer.py", line 566, in get_dataset
    raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ❌ {e}")) from e
RuntimeError: Dataset 'data.yaml' error ❌ 'data.yaml' does not exist
[2025-01-14T04:48:20.687+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:48:20.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/craw_check_update.py took 3.834 seconds
[2025-01-14T04:48:51.239+0000] {processor.py:186} INFO - Started process (PID=2782) to work on /opt/airflow/dags/craw_check_update.py
[2025-01-14T04:48:51.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/craw_check_update.py for tasks to queue
[2025-01-14T04:48:51.243+0000] {logging_mixin.py:190} INFO - [2025-01-14T04:48:51.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/craw_check_update.py
